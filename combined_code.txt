----- File: ./scene_processor.py -----
# File: scene_processor.py
import logging
import json
from typing import Dict, Any, List

from baml_client import b
from baml_client.type_builder import TypeBuilder
from baml_client.types import (
    Agent,
    Organization,
    Location,
    Object,
    Event,
    AgentParticipation,
    ObjectInvolvement
)

from context import GlobalContext
from utils import format_scene_text, generate_uuid, normalize_identifier, is_close_match

async def process_scene_entities(scene: Dict[str, Any], global_context: GlobalContext, scene_number: int) -> str:
    """
    First pass: Extracts and registers entities in dependency order.
    """
    scene_text = format_scene_text(scene)
    story_summary = global_context.get_story_summary()
    tb = TypeBuilder()

    # 1. Extract and Register Locations
    locations = await b.ExtractLocations(
        scene_text=scene_text,
        story_context=story_summary,
        scene_number=scene_number,
        baml_options={"tb": tb}
    )
    for loc in locations:
        global_context.entity_registry.register(loc, "locations")

    # 2. Extract and Register Organizations
    organizations = await b.ExtractOrganizations(
        scene_text=scene_text,
        story_context=story_summary,
        scene_number=scene_number,
        agents=[],  # No agents at this point
        organizations=list(global_context.entity_registry.organizations.values()),
        baml_options={"tb": tb}
    )
    for org in organizations:
        global_context.entity_registry.register(org, "organizations")

    # 3. Extract and Register Agents (using resolved organizations)
    org_enum = tb.add_enum("OrganizationEnum")
    for org in global_context.entity_registry.organizations.values():
        org_enum.add_value(org.uuid)

    # Get the agent name to UUID mapping *before* extracting agents.
    agent_name_to_uuid_mapping = global_context.entity_registry.get_agent_name_to_uuid_mapping()

    # --- Debugging Prints ---
    print("--- Scene Text ---")
    print(scene_text)
    print("--- Story Summary ---")
    print(story_summary)
    print("--- Agent Name to UUID Mapping ---")
    print(agent_name_to_uuid_mapping)

    # IMPORTANT: Supply the mapping as a required positional parameter!
    agents_call = b.ExtractAgents(
        scene_text=scene_text,
        story_context=story_summary,
        agent_name_to_uuid_mapping=agent_name_to_uuid_mapping,  # <-- now provided correctly
        scene_number=scene_number,
        organizations=list(global_context.entity_registry.organizations.values()),
        baml_options={"tb": tb}
    )

    # Await the result from the BAML call.
    agents = await agents_call

    # (If you need to debug the rendered prompt, check your BAML client documentation;
    # usually the awaitable returns the extracted agents and not a prompt property.)

    for agent in agents:
        global_context.entity_registry.register(agent, "agents")

    # 4. Extract and Register Objects (using resolved agents)
    agent_enum = tb.add_enum("AgentEnum")
    for agent in global_context.entity_registry.agents.values():
        agent_enum.add_value(agent.uuid)

    objects = await b.ExtractObjects(
        scene_text=scene_text,
        story_context=story_summary,
        scene_number=scene_number,
        agents=list(global_context.entity_registry.agents.values()),
        baml_options={"tb": tb}
    )
    for obj in objects:
        global_context.entity_registry.register(obj, "objects")

    # Generate a UUID for the scene.
    scene_uuid = generate_uuid("scene", str(scene_number))
    return scene_uuid



def validate_event_references(event: Event, global_context: GlobalContext) -> bool:
    """Validates all entity references in an event."""
    valid = True
    
    # Validate agent participations
    for participation_id in event.agent_participations:
        if not global_context.entity_registry.find_entity_by_uuid(participation_id):
            logging.error(f"Invalid agent participation reference: {participation_id}")
            valid = False
            
    # Validate object involvements  
    for involvement_id in event.object_involvements:
        if not global_context.entity_registry.find_entity_by_uuid(involvement_id):
            logging.error(f"Invalid object involvement reference: {involvement_id}")
            valid = False
            
    return valid

async def process_scene_data(scene: Dict[str, Any], global_context: GlobalContext, scene_number: int, scene_uuid: str) -> Dict[str, Any]:
    """
    Second pass: Extracts Scene Metadata, Events, AgentParticipations, and ObjectInvolvements,
    using the already reconciled entities from the global_context.
    """
    scene_text = format_scene_text(scene)
    registry_context = global_context.get_registry_context()
    tb = TypeBuilder()

    # 1. Extract Scene Metadata (using resolved locations)
    location_enum = tb.add_enum("LocationEnum")
    for loc in global_context.entity_registry.locations.values():
        location_enum.add_value(loc.uuid)

    metadata = await b.ExtractSceneMetadata(
        scene_text=scene_text,
        story_context=global_context.get_story_summary(),
        scene_number=scene_number,
        locations=list(global_context.entity_registry.locations.values()), # Pass the locations
        baml_options={"tb": tb}
    )
    metadata.uuid = scene_uuid  # Assign previously generated scene_uuid

    # Normalize the location field
    if metadata and metadata.location:
        normalized_location = "location-" + normalize_identifier(metadata.location)
        registered_location = global_context.entity_registry.get_location(normalized_location)
        if registered_location:
            metadata.location = registered_location.uuid
        else:
            found = False
            for loc in global_context.entity_registry.locations.values():
                if is_close_match(normalized_location, loc.uuid):
                    metadata.location = loc.uuid
                    found = True
                    break
            if not found:
                metadata.location = None

    # 2. Extract Events
    events = await b.ExtractEvents(
        scene_text=scene_text,
        story_context=registry_context,  # Use registry context
        scene_number=scene_number, #Pass the scene_number
        baml_options={"tb": tb}
    )
    # Generate event UUIDs after extracting events.
    for event in events:
        if not validate_event_references(event, global_context):
            logging.error(f"Invalid references in event {event.uuid}")
        event.uuid = generate_uuid(f"event-{scene_number}", str(event.sequence_within_scene))

    # Sort events by their sequence number and update next_event for each event.
    events.sort(key=lambda e: e.sequence_within_scene)
    for i, event in enumerate(events):
        if i < len(events) - 1:
            event.next_event = events[i+1].uuid
        else:
            event.next_event = None


    # 3. Extract AgentParticipations (using resolved agents and events)
    agent_enum = tb.add_enum("AgentEnum")
    for agent in global_context.entity_registry.agents.values():
        agent_enum.add_value(agent.uuid)
    event_enum = tb.add_enum("EventEnum")
    for event in events:
      event_enum.add_value(event.uuid)

    agent_participations: List[AgentParticipation] = []
    for event in events:
        agent_participations_for_event = await b.ExtractAgentParticipations(
            scene_text=scene_text,
            story_context=registry_context,  # Use registry context
            event=event,
            agents=list(global_context.entity_registry.agents.values()),  # Pass pre-extracted agents
            scene_number=scene_number, # Pass the scene number
            baml_options={"tb": tb}
        )
        for participation in agent_participations_for_event:
            if participation.agent:
                participation.uuid = generate_uuid("agentparticipation", f"{participation.agent}-{event.uuid}")
                agent_participations.append(participation)


    # 4. Extract ObjectInvolvements (using resolved objects and events)
    object_enum = tb.add_enum("ObjectEnum")
    for obj in global_context.entity_registry.objects.values():
        object_enum.add_value(obj.uuid)

    object_involvements: List[ObjectInvolvement] = []
    for event in events:
        object_involvements_for_event = await b.ExtractObjectInvolvements(
            scene_text=scene_text,
            story_context=registry_context,  # Use registry context
            event=event,
            objects=list(global_context.entity_registry.objects.values()),  # Pass pre-extracted objects
            scene_number=scene_number,  # Pass the scene number
            baml_options={"tb": tb}
        )
        for involvement in object_involvements_for_event:
            if involvement.object:
                involvement.uuid = generate_uuid("objectinvolvement", f"{involvement.object}-{event.uuid}")
                object_involvements.append(involvement)

    # Update each event with the IDs of the participation/involvement records.
    for event in events:
        event.agent_participations = [p.uuid for p in agent_participations if p.event == event.uuid]
        event.object_involvements = [i.uuid for i in object_involvements if i.event == event.uuid]

    # Assemble the extracted data.
    extracted_data = {
        "metadata": metadata.model_dump() if metadata else {},
        "events": [e.model_dump() for e in events],
        "agent_participations": [p.model_dump() for p in agent_participations],
        "object_involvements": [i.model_dump() for i in object_involvements]
    }

    # Build the final scene output.
    processed_scene = {
        "scene_uuid": scene_uuid,
        "original_scene_data": scene,
        "extracted_data": extracted_data
    }
    return processed_scene

----- File: ./concatenate.py -----
import os
import glob


def concatenate_python_files(folder_path, output_file="combined_code.txt"):
    """
    Concatenates all Python files in a folder into a single text file.

    Args:
        folder_path: The path to the folder containing the Python files.
        output_file: The name of the output text file (default: "combined_code.txt").
    """

    if not os.path.isdir(folder_path):
        print(f"Error: '{folder_path}' is not a valid directory.")
        return

    python_files = glob.glob(os.path.join(folder_path, "*.py"))
    
    # Add the specific .baml file
    baml_file = "/home/user/langchain/baml_src/myth06.baml"
    all_files_to_concatenate = python_files + [baml_file]

    if not python_files:
        print(f"No Python files found in '{folder_path}'.")
        return

    try:
        with open(output_file, "w", encoding="utf-8") as outfile:
            for file_path in all_files_to_concatenate:
                if os.path.exists(file_path):
                    try:
                        with open(file_path, "r", encoding="utf-8") as infile:
                            outfile.write(f"----- File: {file_path} -----\n")
                            outfile.write(infile.read())
                            outfile.write("\n\n")
                    except UnicodeDecodeError:
                        print(f"Warning: Could not decode file {file_path} using utf-8, skipping this file")
                else:
                  print(f"Warning: Could not find file {file_path}, skipping")

            

            


        print(f"Successfully concatenated {len(python_files)} Python files into '{output_file}'.")

    except Exception as e:
        print(f"An error occurred: {e}")

# Example usage:
folder_to_scan = "."  # Replace with the actual folder path if needed.
concatenate_python_files(folder_to_scan)


----- File: ./episode_processor.py -----
# File: episode_processor.py
import asyncio
import logging
from typing import Dict, Any

from scene_processor import process_scene_entities, process_scene_data  # Import both functions
from context import GlobalContext
from utils import format_scene_text, generate_uuid # Import the missing functions

# Configure logging
logging.basicConfig(filename='episode_processing.log', level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

async def process_episode(episode: Dict[str, Any], global_context: GlobalContext) -> Dict[str, Any]:
    """
    Process a single episode by iterating over its scenes.
    Supports both direct scene arrays and nested acts.
    Uses a two-pass approach:
    1. process_scene_entities (extracts entities in dependency order)
    2. process_scene_data (extracts events, participations, using reconciled entities)
    """
    processed_scenes = []
    episode_title = episode.get("Episode", "Untitled Episode")

    logging.info(f"Starting processing for episode: {episode_title}")

    # --- First Pass: Extract Entities ---
    scene_uuids = []  # Store scene UUIDs for the second pass
    if "Acts" in episode:
        scene_number = 0
        for act_index, act in enumerate(episode.get("Acts", [])):
            act_scenes = act.get("Scenes", [])
            logging.info(f"Processing act {act_index + 1} (entity extraction)")
            for scene in act_scenes:
                scene_number += 1
                logging.info(f"Processing scene {scene_number} (entity extraction): {scene.get('Scene', 'Unnamed Scene')}")
                try:
                    scene_uuid = await process_scene_entities(scene, global_context, scene_number)
                    scene_uuids.append((scene_number, scene_uuid))  # Store scene number and UUID
                except Exception as e:
                    logging.error(f"Error processing scene {scene_number} (entity extraction): {e}", exc_info=True)
                    # Consider skipping the scene on error

    elif "Scenes" in episode:
        scene_number = 0
        for scene in episode.get("Scenes", []):
            scene_number += 1
            logging.info(f"Processing scene {scene_number} (entity extraction): {scene.get('Scene', 'Unnamed Scene')}")
            try:
                scene_uuid = await process_scene_entities(scene, global_context, scene_number)
                scene_uuids.append((scene_number, scene_uuid)) # Store scene number and UUID
            except Exception as e:
                logging.error(f"Error processing scene {scene_number} (entity extraction): {e}", exc_info=True)
            # Consider skipping the scene on error
    else:
        logging.error(f"Episode structure not recognized: must contain 'Scenes' or 'Acts'.")
        raise ValueError("Episode structure not recognized: must contain 'Scenes' or 'Acts'.")


    # --- Second Pass: Extract Scene Data ---
    logging.info(f"Starting second pass (event/participation extraction) for episode: {episode_title}")
    for scene_number, scene_uuid in scene_uuids:
        # Find the original scene data based on scene_number
        original_scene = None
        if "Acts" in episode:
            for act in episode.get("Acts", []):
                for scene in act.get("Scenes", []):
                    # Format the scene text and check if it matches the UUID
                    temp_scene_text = format_scene_text(scene)
                    temp_scene_uuid = generate_uuid("scene", str(scene_number))  # Generate UUID the same way
                    if temp_scene_uuid == scene_uuid:
                        original_scene = scene
                        break
                if original_scene:
                    break
        elif "Scenes" in episode:
            for scene in episode.get("Scenes", []):
                temp_scene_text = format_scene_text(scene)
                temp_scene_uuid = generate_uuid("scene", str(scene_number))
                if temp_scene_uuid == scene_uuid:
                    original_scene = scene
                    break

        if original_scene is None:
            logging.error(f"Could not find original scene data for scene number {scene_number} (UUID: {scene_uuid})")
            continue # Or raise an exception if you want to halt processing

        logging.info(f"Processing scene {scene_number} (event/participation extraction)")
        try:
            logging.info(f"Calling process_scene_data for scene {scene_number} with UUID {scene_uuid}") #NEW LOGGING STATEMENT
            processed_scene = await process_scene_data(original_scene, global_context, scene_number, scene_uuid)
            logging.info(f"process_scene_data completed for scene {scene_number}") # NEW LOGGING STATEMENT
            processed_scenes.append(processed_scene)
        except Exception as e:
            logging.error(f"Error processing scene {scene_number} (event/participation extraction): {e}", exc_info=True)
            # Consider skipping the scene

     # Update each scene’s metadata to point to the next scene’s UUID.
    for i in range(len(processed_scenes) - 1):
        current_scene_metadata = processed_scenes[i]["extracted_data"]["metadata"]
        next_scene_uuid = processed_scenes[i+1]["scene_uuid"]
        current_scene_metadata["next_scene"] = next_scene_uuid
    if processed_scenes:
        processed_scenes[-1]["extracted_data"]["metadata"]["next_scene"] = None

    logging.info(f"Finished processing episode: {episode_title}")

    processed_episode = {
        "episode_title": episode_title,
        "scenes": processed_scenes
    }

    return processed_episode

----- File: ./validation.py -----
# File: validation.py
import logging
from typing import Any, Dict, Optional, Set, List, Union
from baml_client.types import Agent, Organization, Location, Object, Event, AgentParticipation, ObjectInvolvement
from context import GlobalContext
from dataclasses import dataclass
from entity_registry import EntityRegistry

@dataclass
class ValidationResult:
    """Represents the result of validating an entity or reference."""
    is_valid: bool
    errors: List[str]
    warnings: List[str]

def validate_entity_references(
    entity_refs: List[str],
    entity_type: str,
    registry: EntityRegistry
) -> ValidationResult:
    """
    Validates a list of entity references against the registry.
    """
    result = ValidationResult(is_valid=True, errors=[], warnings=[])
    
    for ref in entity_refs:
        if not registry.find_entity_by_uuid(ref):
            result.is_valid = False
            result.errors.append(f"Invalid {entity_type} reference: {ref}")
            
    return result


def validate_entity_attributes(entity: Any) -> bool:
    """
    Validates the attributes of an entity (Agent, Organization, Location, Object).

    Args:
        entity: The entity to validate.

    Returns:
        True if the entity is valid, False otherwise.
    """
    if isinstance(entity, Agent):
        if not entity.uuid or not entity.uuid.startswith("agent-"):
            logging.error(f"Invalid agent UUID: {entity.uuid}")
            return False
        if not entity.name:
            logging.error(f"Agent {entity.uuid} has no name.")
            return False
        if entity.affiliated_org and not entity.affiliated_org.startswith("org-"):
            logging.error(f"Agent {entity.uuid} has invalid affiliated_org: {entity.affiliated_org}")
            return False

    elif isinstance(entity, Organization):
        if not entity.uuid or not entity.uuid.startswith("org-"):
            logging.error(f"Invalid organization UUID: {entity.uuid}")
            return False
        if not entity.name:
            logging.error(f"Organization {entity.uuid} has no name.")
            return False
        # Add more Organization-specific checks if needed

    elif isinstance(entity, Location):
        if not entity.uuid or not entity.uuid.startswith("location-"):
            logging.error(f"Invalid location UUID: {entity.uuid}")
            return False
        if not entity.name:
            logging.error(f"Location {entity.uuid} has no name.")
            return False

    elif isinstance(entity, Object):
        if not entity.uuid or not entity.uuid.startswith("object-"):
            logging.error(f"Invalid object UUID: {entity.uuid}")
            return False
        if not entity.name:
            logging.error(f"Object {entity.uuid} has no name.")
            return False

    else:
        logging.error(f"Unknown entity type: {type(entity)}")
        return False

    return True

def validate_relationships(global_context: GlobalContext) -> bool: # Pass GlobalContext
    """
    Validates the relationships in the entity registry.
    """
    all_valid = True
    entity_registry = global_context.entity_registry

    # Agent.affiliated_org -> Organization.members []
    for agent in entity_registry.agents.values():
        if agent.affiliated_org:
            org = entity_registry.get_organization(agent.affiliated_org)
            if not org:
                logging.error(f"Validation Error: Agent {agent.uuid} has affiliated_org '{agent.affiliated_org}' but organization not found.")
                all_valid = False
            elif agent.uuid not in (org.members or []): # Check if agent UUID is in org members
                logging.error(f"Validation Error: Agent {agent.uuid} affiliated_org '{agent.affiliated_org}' but agent not in organization members.")
                all_valid = False

    # Object.original_owner -> Agent.uuid
    for obj in entity_registry.objects.values():
        if obj.original_owner:
            owner_agent = entity_registry.get_agent(obj.original_owner)
            if not owner_agent:
                logging.error(f"Validation Error: Object {obj.uuid} has original_owner '{obj.original_owner}' but agent not found.")
                all_valid = False

    # ObjectInvolvement.object -> Object.uuid
    for event_data in global_context.processed_episodes:
        for scene_data in event_data["scenes"]:
            for involvement_data in scene_data["extracted_data"]["object_involvements"]:
                if not validate_object_involvement(involvement_data, entity_registry):
                  all_valid = False

    # AgentParticipation.agent -> Agent.uuid
    for event_data in global_context.processed_episodes:
        for scene_data in event_data["scenes"]:
            for participation_data in scene_data["extracted_data"]["agent_participations"]:
                if not validate_agent_participation(participation_data, entity_registry):
                  all_valid = False

    # SceneMetadata.location -> Location.uuid
    for event_data in global_context.processed_episodes:
        for scene_data in event_data["scenes"]:
            metadata_data = scene_data["extracted_data"]["metadata"]
            if metadata_data and metadata_data.get("location"): # Check if metadata and location exist
                location_uuid = metadata_data["location"]
                location = entity_registry.get_location(location_uuid)
                if not location:
                    logging.error(f"Validation Error: SceneMetadata {metadata_data.get('uuid')} refers to location '{location_uuid}' but location not found.")
                    all_valid = False

    # Event.agent_participations -> AgentParticipation.uuid [] (Forward reference check - UUIDs are generated later, can't fully validate here)
    # Event.object_involvements -> ObjectInvolvement.uuid [] (Forward reference check - UUIDs are generated later, can't fully validate here)
    # SceneMetadata.scene_number -> scene_number (variable) - Covered by other validation
    # Scene.scene_number -> scene_number (variable) - Covered by other validation
    # Scene.next_scene -> Scene.uuid (of next scene) or null (more complex, can add later if needed)
    # Event.next_event -> Event.uuid (of next event) or null (more complex, can add later if needed)


    return all_valid


def validate_scene_consistency(scene_data: Dict[str, Any]) -> bool:
    """
    Performs consistency checks within a scene.

    Args:
        scene_data: The processed scene data.

    Returns:
        True if the scene is consistent, False otherwise.
    """
    # Add scene consistency checks here (e.g., event sequence numbers, agent/object references)
    return True

def validate_all(global_context: "GlobalContext") -> bool:
    """
    Performs all validations on the given global context.
    """
    all_valid = True

    # Validate entity attributes
    for entity_type, entities in global_context.entity_registry.get_all_entities().items():
        for entity in entities:
            if not validate_entity_attributes(entity):
                logging.error(f"Invalid entity: {entity_type} - {entity.uuid}")
                all_valid = False

    # Validate relationships - CALL THE NEW FUNCTION
    if not validate_relationships(global_context): # Call the new relationship validation
        all_valid = False

    # Validate scene consistency (currently a placeholder)
    for episode in global_context.processed_episodes:
        for scene in episode["scenes"]:
            if not validate_scene_consistency(scene):
                all_valid = False

    return all_valid

def validate_organization_consistency(self) -> None:
    """Validates and optionally fixes org/agent consistency"""
    for agent in self.agents.values():
        if agent.affiliated_org:
            org = self.get_organization(agent.affiliated_org)
            if org:
                if agent.uuid not in (org.members or []):
                    # Option to add agent to org members
                    if org.members is None:
                        org.members = []
                    org.members.append(agent.uuid)
            else:
                # Clear invalid reference
                agent.affiliated_org = None

def validate_object_involvement(involvement_data: Dict[str, Any], entity_registry: EntityRegistry) -> bool:
    """
    Validates an ObjectInvolvement record.
    """
    if not involvement_data.get("object"):
        logging.error(f"Invalid ObjectInvolvement data: Missing 'object' field.")
        return False

    if not involvement_data.get("event"):
        logging.error(f"Invalid ObjectInvolvement data: Missing 'event' field.")
        return False

    involved_object = entity_registry.get_object(involvement_data["object"])
    if not involved_object:
        logging.error(f"Validation Error: ObjectInvolvement refers to object '{involvement_data['object']}' but object not found.")
        return False

    # Ensure event UUID is valid
    if not involvement_data["event"].startswith("event-"):
        logging.error(f"Validation Error: ObjectInvolvement refers to event '{involvement_data['event']}' with invalid UUID format.")
        return False

    return True

def validate_agent_participation(participation_data: Dict[str, Any], entity_registry: EntityRegistry) -> bool:
    """
    Validates an AgentParticipation record.
    """
    if not participation_data.get("agent"):
        logging.error(f"Invalid AgentParticipation data: Missing 'agent' field.")
        return False

    if not participation_data.get("event"):
        logging.error(f"Invalid AgentParticipation data: Missing 'event' field.")
        return False

    participating_agent = entity_registry.get_agent(participation_data["agent"])
    if not participating_agent:
        logging.error(f"Validation Error: AgentParticipation refers to agent '{participation_data['agent']}' but agent not found.")
        return False

    # Ensure event UUID is valid
    if not participation_data["event"].startswith("event-"):
        logging.error(f"Validation Error: AgentParticipation refers to event '{participation_data['event']}' with invalid UUID format.")
        return False

    return True

def validate_agent_affiliations(entity_registry: EntityRegistry) -> ValidationResult:
    """
    Validates bidirectional consistency between agent affiliations and org members.
    """
    result = ValidationResult(is_valid=True, errors=[], warnings=[])
    
    # Check agent -> org references
    for agent in entity_registry.agents.values():
        if agent.affiliated_org:
            org = entity_registry.get_organization(agent.affiliated_org)
            if not org:
                result.is_valid = False
                result.errors.append(
                    f"Agent {agent.name} ({agent.uuid}) references non-existent "
                    f"organization: {agent.affiliated_org}"
                )
            elif not org.members or agent.uuid not in org.members:
                result.is_valid = False
                result.errors.append(
                    f"Agent {agent.name} ({agent.uuid}) claims affiliation with "
                    f"org {org.name} but is not in its members list"
                )

    # Check org -> agent references 
    for org in entity_registry.organizations.values():
        if org.members:
            for member_uuid in org.members:
                agent = entity_registry.get_agent(member_uuid)
                if not agent:
                    result.is_valid = False
                    result.errors.append(
                        f"Organization {org.name} ({org.uuid}) references "
                        f"non-existent agent: {member_uuid}"
                    )
                elif agent.affiliated_org != org.uuid:
                    result.is_valid = False
                    result.errors.append(
                        f"Organization {org.name} claims agent {agent.name} as member "
                        f"but agent's affiliated_org doesn't match"
                    )
                    
    return result


def validate_participation_references(
    scene_data: Dict[str, Any],
    registry: EntityRegistry
) -> ValidationResult:
    """Validates participation and involvement references within a scene."""
    result = ValidationResult(is_valid=True, errors=[], warnings=[])

    # Event -> AgentParticipation/ObjectInvolvement
    for event in scene_data.get("events", []):
        # Validate agent participations
        for participation_id in event.get("agent_participations", []):
            participation = next(
                (p for p in scene_data.get("agent_participations", [])
                 if p["uuid"] == participation_id),
                None
            )
            if not participation:
                result.errors.append(
                    f"Event {event['uuid']} references non-existent "
                    f"participation: {participation_id}"
                )
                result.is_valid = False
            elif not registry.get_agent(participation["agent"]):
                result.errors.append(
                    f"Participation {participation_id} references non-existent "
                    f"agent: {participation['agent']}"
                )
                result.is_valid = False

        # Validate object involvements
        for involvement_id in event.get("object_involvements", []):
            involvement = next(
                (i for i in scene_data.get("object_involvements", [])
                 if i["uuid"] == involvement_id),
                None
            )
            if not involvement:
                result.errors.append(
                    f"Event {event['uuid']} references non-existent "
                    f"involvement: {involvement_id}"
                )
                result.is_valid = False
            elif not registry.get_object(involvement["object"]):
                result.errors.append(
                    f"Involvement {involvement_id} references non-existent "
                    f"object: {involvement['object']}"
                )
                result.is_valid = False

    return result

def validate_bidirectional_relationships(registry: EntityRegistry) -> ValidationResult:
    """Validates relationships that should be reciprocal."""
    result = ValidationResult(is_valid=True, errors=[], warnings=[])
    
    # Agent <-> Organization
    for agent in registry.agents.values():
        if agent.affiliated_org:
            org = registry.get_organization(agent.affiliated_org)
            if not org:
                result.errors.append(
                    f"Agent {agent.name} ({agent.uuid}) references non-existent "
                    f"organization: {agent.affiliated_org}"
                )
                result.is_valid = False
            elif not org.members or agent.uuid not in org.members:
                result.errors.append(
                    f"Agent {agent.name} references org {org.name} but is not in "
                    "its members list"
                )
                result.is_valid = False

    return result

def validate_simple_references(registry: EntityRegistry) -> ValidationResult:
    """Validates one-way entity references."""
    result = ValidationResult(is_valid=True, errors=[], warnings=[])
    
    # Object -> Agent (original owner)
    for obj in registry.objects.values():
        if obj.original_owner:
            owner = registry.get_agent(obj.original_owner)
            if not owner:
                result.errors.append(
                    f"Object {obj.name} references non-existent owner: "
                    f"{obj.original_owner}"
                )
                result.is_valid = False

    return result

def validate_sequence_references(
    scenes: List[Dict[str, Any]]
) -> ValidationResult:
    """Validates scene and event sequence references."""
    result = ValidationResult(is_valid=True, errors=[], warnings=[])
    
    scene_uuids = {scene["scene_uuid"] for scene in scenes}
    
    for i, scene in enumerate(scenes):
        # Validate scene sequence
        if i < len(scenes) - 1:
            next_scene = scene["extracted_data"]["metadata"].get("next_scene")
            if not next_scene:
                result.errors.append(
                    f"Scene {scene['scene_uuid']} missing next_scene reference"
                )
                result.is_valid = False
            elif next_scene not in scene_uuids:
                result.errors.append(
                    f"Scene {scene['scene_uuid']} references invalid next_scene: "
                    f"{next_scene}"
                )
                result.is_valid = False
                
        # Validate event sequence within scene
        events = scene["extracted_data"].get("events", [])
        event_uuids = {event["uuid"] for event in events}
        
        for j, event in enumerate(events):
            if j < len(events) - 1:
                next_event = event.get("next_event")
                if not next_event:
                    result.errors.append(
                        f"Event {event['uuid']} missing next_event reference"
                    )
                    result.is_valid = False
                elif next_event not in event_uuids:
                    result.errors.append(
                        f"Event {event['uuid']} references invalid next_event: "
                        f"{next_event}"
                    )
                    result.is_valid = False

    return result

def validate_all_relationships(
    global_context: GlobalContext
) -> ValidationResult:
    """Performs comprehensive validation of all entity relationships."""
    
    registry = global_context.entity_registry
    final_result = ValidationResult(is_valid=True, errors=[], warnings=[])
    
    # Run all validation checks
    validations = [
        validate_bidirectional_relationships(registry),
        validate_simple_references(registry)
    ]
    
    # Add scene-specific validations
    for episode in global_context.processed_episodes:
        for scene in episode["scenes"]:
            validations.extend([
                validate_participation_references(
                    scene["extracted_data"], 
                    registry
                )
            ])
    
    # Add sequence validation
    for episode in global_context.processed_episodes:
        validations.append(
            validate_sequence_references(episode["scenes"])
        )
    
    # Combine all validation results
    for result in validations:
        if not result.is_valid:
            final_result.is_valid = False
            final_result.errors.extend(result.errors)
            final_result.warnings.extend(result.warnings)
    
    return final_result


def validate_all(global_context: "GlobalContext") -> ValidationResult:
    """
    Performs all validations on the given global context.
    """
    final_result = ValidationResult(is_valid=True, errors=[], warnings=[])

    # Validate entity attributes
    for entity_type, entities in global_context.entity_registry.get_all_entities().items():
        for entity in entities:
            if not validate_entity_attributes(entity):
                final_result.errors.append(f"Invalid entity: {entity_type} - {entity.uuid}")
                final_result.is_valid = False

    # Validate all relationships
    relationship_result = validate_all_relationships(global_context)
    if not relationship_result.is_valid:
        final_result.is_valid = False
        final_result.errors.extend(relationship_result.errors)
        final_result.warnings.extend(relationship_result.warnings)

    # Validate scene consistency
    for episode in global_context.processed_episodes:
        for scene in episode["scenes"]:
            if not validate_scene_consistency(scene):
                final_result.errors.append(f"Scene consistency validation failed for scene {scene.get('scene_uuid')}")
                final_result.is_valid = False

    return final_result

----- File: ./main.py -----
# File: main.py
import asyncio
import json
import logging
import sys
from pathlib import Path
from typing import List
from collections import defaultdict

from episode_processor import process_episode
from context import GlobalContext
from validation import (
    ValidationResult,
    validate_all,
    validate_all_relationships,
    validate_agent_affiliations,
    validate_bidirectional_relationships,
    validate_simple_references,
    validate_participation_references,
    validate_sequence_references,
    validate_organization_consistency
)
from utils import normalize_name
from entity_registry import EntityRegistry

# Configure logging
for handler in logging.root.handlers[:]:
    logging.root.removeHandler(handler)
logging.basicConfig(
    filename="fabula_processing.log",
    level=logging.DEBUG,
    format="%(asctime)s - %(levelname)s - %(message)s",
)

# Define paths for input and output files
INPUT_JSON_PATH = Path("/home/user/fabula/source_docs/ai_fanfic/star_trek_tng/echoes_of_the_past_transcript.json")
CONTEXT_FILES = [
    Path("/home/user/fabula/source_docs/ai_fanfic/star_trek_tng/echoes_of_the_past_treatment.txt")
]
OUTPUT_JSON_PATH = Path("/home/user/fabula/output/pre_processed/echoes_of_the_past_graph_GPT4oMini.json")

# INPUT_JSON_PATH = Path("dummy_data/fault_lines_transcript.json")
# CONTEXT_FILES = [
#     Path("dummy_data/fault_lines_novelization.txt")
# ]
# OUTPUT_JSON_PATH = Path("fault_lines_graph.json")

# OUTPUT_JSON_PATH = Path("output/test_graph.json")

# INPUT_JSON_PATH = Path("/home/user/fabula/source_docs/ai_fanfic/peep_show/networking_event_transcript.json")
# CONTEXT_FILES = [
#     Path("/home/user/fabula/source_docs/ai_fanfic/peep_show/networking_event_treatment.txt")
# ]
# OUTPUT_JSON_PATH = Path("networking_event_graph_GPT4o.json")

def load_context_documents(context_files: List[Path]) -> str:
    """Loads and concatenates context documents."""
    context_text = ""
    for filepath in context_files:
        if filepath.exists():
            with open(filepath, "r") as f:
                context_text += f.read() + "\n"
    return context_text

def convert_to_serializable(obj):
    """Recursively convert Pydantic objects to dictionaries for JSON serialization."""
    if isinstance(obj, list):
        return [convert_to_serializable(item) for item in obj]
    elif isinstance(obj, dict):
        return {k: convert_to_serializable(v) for k, v in obj.items()}
    elif hasattr(obj, "model_dump"):
        return obj.model_dump()
    else:
        return obj

async def main():
    """
    Orchestrates the complete processing of a narrative script.
    """
    logging.info("Starting Fabula processing...")

    script_data = None
    context_documents = ""
    
    # First check for command-line input file
    if len(sys.argv) > 1:
        input_path = Path(sys.argv[1])
        if not input_path.exists():
            logging.error(f"Input file not found: {input_path}")
            return
        logging.info(f"Loading script data from: {input_path}")
        try:
            with open(input_path, "r") as f:
                script_data = json.load(f)
        except json.JSONDecodeError as e:
            logging.error(f"Failed to parse JSON from {input_path}: {e}")
            return
            
        # Check for additional context files from command line
        if len(sys.argv) > 2:
            context_files = [Path(filepath) for filepath in sys.argv[2:]]
            context_documents = load_context_documents(context_files)
    
    # If no command line arguments, check for default input file
    elif INPUT_JSON_PATH.exists():
        logging.info(f"Loading script data from default path: {INPUT_JSON_PATH}")
        try:
            with open(INPUT_JSON_PATH, "r") as f:
                script_data = json.load(f)
        except json.JSONDecodeError as e:
            logging.error(f"Failed to parse JSON from {INPUT_JSON_PATH}: {e}")
            return
            
        # Load default context files
        if CONTEXT_FILES:
            context_documents = load_context_documents(CONTEXT_FILES)

    # Skip processing if script_data is None
    if script_data is None:
        logging.error("No script data loaded. Aborting processing.")
        return

    # Initialize GlobalContext with context documents
    global_context = GlobalContext(context_documents)

    episodes = script_data.get("Episodes", [])
    processed_episodes = []

    logging.info("Starting episode processing (two-pass)...")
    for episode_index, episode in enumerate(episodes):
        logging.info(f"Processing episode {episode_index + 1}: {episode.get('Episode', 'Untitled Episode')}")
        processed_episode = await process_episode(episode, global_context)
        processed_episodes.append(processed_episode)
    logging.info("Finished episode processing.")

    # Entity Reconciliation
    logging.info("Starting entity reconciliation...")
    await global_context.entity_registry.reconcile_entities()
    logging.info("Entity reconciliation complete.")

    # Update agent affiliations
    global_context.entity_registry.update_agent_affiliations()

    # After processing episodes, attach them to the global context
    global_context.processed_episodes = processed_episodes

    # Validation
    logging.info("Starting validation...")
    
    # Run all validation checks
    validation_results = [
        validate_all_relationships(global_context),
        validate_agent_affiliations(global_context.entity_registry),
        validate_bidirectional_relationships(global_context.entity_registry),
        validate_simple_references(global_context.entity_registry),
        validate_organization_consistency(global_context.entity_registry)  # Add this
    ]
    
    # Add scene-specific validations
    for episode in global_context.processed_episodes:
        for scene in episode["scenes"]:
            validation_results.append(
                validate_participation_references(
                    scene["extracted_data"],
                    global_context.entity_registry
                )
            )
        validation_results.append(
            validate_sequence_references(episode["scenes"])
        )

    # Combine all validation results
    final_validation = ValidationResult(is_valid=True, errors=[], warnings=[])
    for result in validation_results:
        if not result.is_valid:
            final_validation.is_valid = False
            final_validation.errors.extend(result.errors)
            final_validation.warnings.extend(result.warnings)

    # Log validation results
    if not final_validation.is_valid:
        logging.warning("Validation found issues:")
        for error in final_validation.errors:
            logging.error(f"  - {error}")
        for warning in final_validation.warnings:
            logging.warning(f"  - {warning}")
    else:
        logging.info("Validation successful.")

    # Prepare final output
    final_output = {
        "story_title": script_data.get("Story", "Untitled Story"),
        "airdate": script_data.get("Airdate"),
        "episodes": processed_episodes,
        "entity_registry": global_context.entity_registry.get_all_entities(),
        "validation_results": {
            "is_valid": final_validation.is_valid,
            "errors": final_validation.errors,
            "warnings": final_validation.warnings
        }
    }

    # Convert to JSON-serializable format
    serializable_output = convert_to_serializable(final_output)

    # Write output to file
    with open(OUTPUT_JSON_PATH, "w") as f:
        json.dump(serializable_output, f, indent=4)
    logging.info(f"Fabula processing complete. Output written to {OUTPUT_JSON_PATH}")

if __name__ == "__main__":
    asyncio.run(main())

----- File: ./post_processor.py -----
# post_processor.py
from typing import Dict, Any, Union
from entity_normalizer import EntityNormalizer
import logging

logger = logging.getLogger(__name__)

def clean_entity_references(data: Dict[str, Any]) -> Dict[str, Any]:
    """Clean up entity references in the extracted data."""
    if 'entity_registry' in data:
        # Build a map of normalized names to correct entity types
        entity_map = {}
        for entity_type in ['agents', 'objects', 'locations', 'organizations']:
            registry = data['entity_registry'].get(entity_type, {})
            for uuid, entity in registry.items():
                normalized_name = EntityNormalizer.normalize_name(entity['name'])
                if normalized_name in entity_map:
                    logger.warning(
                        f"Found duplicate entity '{normalized_name}' as both "
                        f"{entity_map[normalized_name][0]} and {entity_type}"
                    )
                entity_map[normalized_name] = (entity_type, uuid)

        # Clean up references using the map
        for entity_type in ['agents', 'objects', 'locations', 'organizations']:
            registry = data['entity_registry'].get(entity_type, {})
            clean_registry = {}
            for uuid, entity in registry.items():
                normalized_name = EntityNormalizer.normalize_name(entity['name'])
                correct_type, correct_uuid = entity_map.get(normalized_name, (entity_type, uuid))
                if correct_type == entity_type:
                    clean_registry[uuid] = entity
            data['entity_registry'][entity_type] = clean_registry

    return data

def clean_scene_references(scene_data: Dict[str, Any], normalizer: EntityNormalizer) -> None:
    """Clean up references within a scene's extracted data."""
    # Clean metadata location reference
    if 'metadata' in scene_data and scene_data['metadata'].get('location'):
        location_ref = normalizer.extract_uuid(scene_data['metadata']['location'])
        if not normalizer.validate_reference(location_ref):
            try:
                scene_data['metadata']['location'] = normalizer.normalize_reference(
                    'location', location_ref
                )
            except Exception as e:
                logger.warning(f"Failed to normalize location reference: {e}")
                scene_data['metadata']['location'] = None

    # Clean event references
    if 'events' in scene_data:
        for event in scene_data['events']:
            # Clean agent participations
            if 'agent_participations' in event:
                cleaned_participations = []
                for ap in event['agent_participations']:
                    ap_ref = normalizer.extract_uuid(ap)
                    if normalizer.validate_reference(ap_ref):
                        cleaned_participations.append(ap_ref)
                event['agent_participations'] = cleaned_participations

            # Clean object involvements
            if 'object_involvements' in event:
                cleaned_involvements = []
                for oi in event['object_involvements']:
                    oi_ref = normalizer.extract_uuid(oi)
                    if normalizer.validate_reference(oi_ref):
                        cleaned_involvements.append(oi_ref)
                event['object_involvements'] = cleaned_involvements

    # Clean agent participations
    if 'agent_participations' in scene_data:
        for ap in scene_data['agent_participations']:
            if 'agent' in ap:
                agent_ref = normalizer.extract_uuid(ap['agent'])
                if not normalizer.validate_reference(agent_ref):
                    try:
                        ap['agent'] = normalizer.normalize_reference('agent', agent_ref)
                    except Exception as e:
                        logger.warning(f"Failed to normalize agent reference: {e}")
                        ap['agent'] = None

    # Clean object involvements
    if 'object_involvements' in scene_data:
        for oi in scene_data['object_involvements']:
            if 'object' in oi:
                object_ref = normalizer.extract_uuid(oi['object'])
                if not normalizer.validate_reference(object_ref):
                    try:
                        oi['object'] = normalizer.normalize_reference('object', object_ref)
                    except Exception as e:
                        logger.warning(f"Failed to normalize object reference: {e}")
                        oi['object'] = None


def update_event_involvements(data: Dict) -> Dict:
    """Update object involvement counts based on events."""
    object_involvements = {}
    
    # Count involvements across all scenes
    for episode in data['episodes']:
        for scene in episode['scenes']:
            if 'extracted_data' in scene:
                for event in scene['extracted_data'].get('events', []):
                    for obj_uuid in event.get('object_involvements', []):
                        object_involvements[obj_uuid] = object_involvements.get(obj_uuid, 0) + 1
    
    # Update objects with involvement counts
    if 'entity_registry' in data and 'objects' in data['entity_registry']:
        for obj_uuid in data['entity_registry']['objects']:
            if obj_uuid in object_involvements:
                data['entity_registry']['objects'][obj_uuid]['event_involvements'] = object_involvements[obj_uuid]
            else:
                data['entity_registry']['objects'][obj_uuid]['event_involvements'] = 0
    
    return data

----- File: ./context.py -----
# context.py

import uuid
from typing import Dict, Any, List, Union, Type, Optional, cast
from baml_client.types import Agent, Organization, Location, Object
from utils import normalize_identifier, is_close_match, generate_uuid
from entity_registry import EntityRegistry # <---- CORRECTED IMPORT STATEMENT

def normalize_name(name: str) -> str:
    """
    Normalize an entity name by stripping whitespace and converting to lowercase.
    """
    return name.strip().lower() if name else ""

class GlobalContext:
    """
    The GlobalContext holds story-wide shared state, including:
      - The entity registry, which tracks all agents, objects, locations, and organizations.
      - Scene summaries to help build a cohesive story context for BAML calls.
    """

    def __init__(self, context_documents: str = ""):
        self.entity_registry = EntityRegistry()
        # Keep a list of scene metadata summaries (for example, scene titles).
        self.scene_summaries: List[Dict[str, Any]] = []
        self.context_documents = context_documents
        self.processed_episodes: List[Any] = []

    def update_with_scene(self, extracted_data: Dict[str, Any]) -> None:
        """
        Update the global context using extracted data from a scene.
        Typically, we add the scene metadata to our context.
        """
        metadata = extracted_data.get("metadata", {})
        if metadata:
            self.scene_summaries.append(metadata)

    def get_story_summary(self) -> str:
        """
        Generates a summary string of the current story context based on the global context.
        Includes scene summaries and optionally context documents.
        """
        summary_lines = []

        # Add context documents to the summary
        if self.context_documents:
            summary_lines.append("Context Documents:")
            summary_lines.append(self.context_documents)

        # Summarize scene metadata
        if self.scene_summaries:
            summary_lines.append("Scene Summaries:")
            for scene_data in self.scene_summaries:
                summary_lines.append(
                    f"  Scene: {scene_data.get('title', 'Untitled')}, UUID: {scene_data.get('uuid', 'N/A')}, Location: {scene_data.get('location', 'N/A')}"
                )

        return "\n".join(summary_lines)

    def get_registry_context(self) -> str:
        """
        Generates a context string summarizing the current state of the entity registry.
        """
        summary_lines = []

        # Summarize entities
        entities = self.entity_registry.get_all_entities()
        for entity_type, entity_list in entities.items():
            if entity_list:
                summary_lines.append(f"{entity_type.capitalize()}:")
                for entity in entity_list:
                    if entity_type == "agents":
                        summary_lines.append(
                            f"  Agent: {entity.name}, UUID: {entity.uuid}, Affiliated Org: {entity.affiliated_org}"
                        )
                    elif entity_type == "organizations":
                        summary_lines.append(
                            f"  Organization: {entity.name}, UUID: {entity.uuid}, Members: {', '.join(entity.members or [])}"
                        )
                    elif entity_type == "locations":
                        summary_lines.append(
                            f"  Location: {entity.name}, UUID: {entity.uuid}, Type: {entity.type}"
                        )
                    elif entity_type == "objects":
                        summary_lines.append(
                            f"  Object: {entity.name}, UUID: {entity.uuid}, Original Owner: {entity.original_owner}"
                        )

        return "\n".join(summary_lines)

----- File: ./entity_registry.py -----
# entity_registry.py
from typing import Dict, Any, List, Union, cast, Optional
import logging
from thefuzz import fuzz
from baml_client.types import Agent, Organization, Location, Object, ResolvedAgent, ResolvedOrganization, ResolvedLocation, ResolvedObject
from utils import generate_uuid, normalize_identifier, normalize_name, normalize_for_matching, is_close_match
from baml_client import b
from collections import defaultdict

class EntityRegistry:
    """
    Maintains distinct collections of primary entities (agents, organizations, locations, objects)
    using native BAML types. Ensures consistent entity references.
    """

    def __init__(self):
        self.agents: Dict[str, Agent] = {}
        self.organizations: Dict[str, Organization] = {}
        self.locations: Dict[str, Location] = {}
        self.objects: Dict[str, Object] = {}
        self.processed_episodes: List[Dict[str, Any]] = []  # Initialize processed_episodes


    def register(self, entity: Any, entity_type: str) -> None:
        """Registers or merges an entity into the registry based on type."""
        logging.debug(f"Registering entity of type: {entity_type}")
        if entity_type == "agents":
            self._register_agent(cast(Agent, entity))
        elif entity_type == "organizations":
            self._register_organization(cast(Organization, entity))
        elif entity_type == "locations":
            self._register_location(cast(Location, entity))
        elif entity_type == "objects":
            self._register_object(cast(Object, entity))
        else:
            logging.error(f"Unknown entity type: {entity_type}")
            raise ValueError(f"Unknown entity type: {entity_type}")

    def _register_agent(self, agent: Agent) -> None:
        """Registers or updates an agent, handling duplicates and orgs."""
        
        # 1. Check for existing agent by UUID (fastest and most reliable)
        existing_agent = self.find_entity_by_uuid(agent.uuid)
        if existing_agent:
            self._merge_agent(existing_agent, agent)
            return

        # 2. Check for potential duplicates by name/aliases using normalized matching
        normalized_name = normalize_for_matching(agent.name)
        for existing_agent in self.agents.values():
            if is_close_match(normalized_name, normalize_for_matching(existing_agent.name)):
                self._merge_agent(existing_agent, agent) 
                return
            
            # Check aliases with normalized matching
            if hasattr(agent, "aliases") and agent.aliases:
                for alias in agent.aliases:
                    if is_close_match(normalize_for_matching(alias), 
                                    normalize_for_matching(existing_agent.name)):
                        self._merge_agent(existing_agent, agent)
                        return

        # 3. Add new agent using UUID as key
        logging.debug(f"Adding new agent {agent.name} (Agent ID: {agent.agent_id}) with UUID {agent.uuid} to registry.")
        key = agent.uuid # Use LLM UUID as the key
        self.agents[key] = agent

    def _register_organization(self, org: Organization) -> None:
        """Registers or updates an organization."""
        logging.debug(f"Registering organization: {org.name}")

        # Check for existing by UUID
        existing_org = self.find_entity_by_uuid(org.uuid)
        if existing_org:
            logging.debug(f"Organization with UUID {org.uuid} already exists. Merging...")
            self._merge_organization(existing_org, org)
            return

        # Check for potential duplicates by name (using normalize_for_matching)
        for existing_org in self.organizations.values():
            if is_close_match(org.name, existing_org.name):
                logging.debug(f"Potential duplicate organization found (name match). Merging...")
                self._merge_organization(existing_org, org)
                return

        # Add new organization
        logging.debug(f"Adding new organization {org.name} with UUID {org.uuid}.")
        key = org.uuid # Use LLM UUID for the key
        self.organizations[key] = org

    def _register_location(self, location: Location) -> None:
        """Registers or updates a location."""
        logging.debug(f"Registering location: {location.name}")

        # Check by UUID
        existing_location = self.find_entity_by_uuid(location.uuid)
        if existing_location:
            logging.debug(f"Location {location.name} exists. Merging...")
            self._merge_location(existing_location, location)
            return

        # Check for duplicates by name
        for existing_location in self.locations.values():
            if is_close_match(location.name, existing_location.name):
                 logging.debug(f"Potential duplicate location found (name match). Merging...")
                 self._merge_location(existing_location, location)
                 return

        # Add new
        logging.debug(f"Adding new location {location.name} to registry.")
        key = location.uuid # Use the LLM UUID as the Key
        self.locations[key] = location

    def _register_object(self, obj: Object) -> None:
        """Registers or updates an object."""
        logging.debug(f"Registering object: {obj.name}")

        # Check by UUID
        existing_object = self.find_entity_by_uuid(obj.uuid)
        if existing_object:
            logging.debug(f"Object {obj.name} exists. Merging...")
            self._merge_object(existing_object, obj)
            return

        # Check for duplicates by name
        for existing_object in self.objects.values():
            if is_close_match(obj.name, existing_object.name):
                logging.debug(f"Potential duplicate object found (name match). Merging...")
                self._merge_object(existing_object, obj)
                return

        # Add new
        logging.debug(f"Adding new object {obj.name} to registry.")
        key = obj.uuid # Use LLM UUID as key
        self.objects[key] = obj

    def _merge_agent(self, existing_agent: Agent, new_agent: Agent) -> None:
        """Merges new agent data into existing agent record, preserving existing UUID."""
        
        logging.debug(f"Merging agent {existing_agent.uuid} with new data")
        
        # Core fields - take non-null new values
        if new_agent.name and new_agent.name != existing_agent.name:
            existing_agent.name = new_agent.name
            logging.debug(f"Updated name to: {new_agent.name}")
            
        if new_agent.title and new_agent.title != existing_agent.title:
            existing_agent.title = new_agent.title
            
        # Merge descriptions if both exist
        if existing_agent.description and new_agent.description:
            existing_agent.description = f"{existing_agent.description}\n{new_agent.description}"
        elif new_agent.description:
            existing_agent.description = new_agent.description
            
        # Merge traits as sets
        if new_agent.traits:
            existing_traits = set(existing_agent.traits or [])
            new_traits = set(new_agent.traits)
            existing_agent.traits = list(existing_traits | new_traits)
            
        # Organizational affiliation - prefer more specific over "Unknown"
        if (new_agent.affiliated_org and 
            new_agent.affiliated_org != "Unknown" and
            new_agent.affiliated_org != existing_agent.affiliated_org):
            existing_agent.affiliated_org = new_agent.affiliated_org
            
        # Merge aliases if present
        if hasattr(existing_agent, "aliases") and hasattr(new_agent, "aliases"):
            existing_aliases = set(existing_agent.aliases or [])
            new_aliases = set(new_agent.aliases or [])
            existing_agent.aliases = list(existing_aliases | new_aliases)

    def _merge_organization(self, existing_org: Organization, new_org: Organization) -> None:
        """Merges new organization data into the existing record, KEEPING EXISTING UUID."""
        logging.debug(f"Merging organization {existing_org.uuid} ({existing_org.name}) with new data.")

        if new_org.name and new_org.name != existing_org.name:
            logging.info(f"Updating org name from {existing_org.name} to {new_org.name}")
            existing_org.name = new_org.name
        if new_org.description is not None and new_org.description != existing_org.description:
            existing_org.description = new_org.description
        if new_org.sphere_of_influence and new_org.sphere_of_influence != "Unknown" and new_org.sphere_of_influence != existing_org.sphere_of_influence:
            existing_org.sphere_of_influence = new_org.sphere_of_influence
        if new_org.members:
            existing_org.members = list(
                set(existing_org.members or []) | set(new_org.members)
            )

    def _merge_location(self, existing_location: Location, new_location: Location) -> None:
        """Merges new location data into the existing record, KEEPING EXISTING UUID."""
        logging.debug(f"Merging location {existing_location.uuid} ({existing_location.name}) with new data.")
        if new_location.name and new_location.name != existing_location.name:
            logging.debug(f"Updating location name to {new_location.name}")
            existing_location.name = new_location.name
        if new_location.description is not None and new_location.description != existing_location.description:
            existing_location.description = new_location.description
        if new_location.type is not None and new_location.type != existing_location.type:
            existing_location.type = new_location.type

    def _merge_object(self, existing_obj: Object, new_obj: Object) -> None:
        """Merges new object data into the existing record, KEEPING EXISTING UUID."""
        logging.debug(f"Merging object {existing_obj.uuid} ({existing_obj.name}) with new data.")
        if new_obj.name and new_obj.name != existing_obj.name:
            logging.debug(f"Updating object name to {new_obj.name}")
            existing_obj.name = new_obj.name
        if new_obj.description is not None and new_obj.description != existing_obj.description:
            existing_obj.description = new_obj.description
        if new_obj.purpose is not None and new_obj.purpose != existing_obj.purpose:
            existing_obj.purpose = new_obj.purpose
        if new_obj.significance is not None and new_obj.significance != existing_obj.significance:
            existing_obj.significance = new_obj.significance
        if new_obj.original_owner and new_obj.original_owner != existing_obj.original_owner:
            existing_obj.original_owner = new_obj.original_owner

    def get_agent(self, agent_id: str) -> Optional[Agent]:
        """Retrieves an agent by its ID (using normalize_identifier)."""
        key = normalize_identifier(agent_id)
        return self.agents.get(key)

    def get_organization(self, org_id: str) -> Optional[Organization]:
        """Retrieves an organization by its ID."""
        key = normalize_identifier(org_id)
        return self.organizations.get(key)

    def get_location(self, location_name: str) -> Optional[Location]:
        """Retrieves a location by its name."""
        key = normalize_identifier(location_name)
        return self.locations.get(key)

    def get_object(self, object_name: str) -> Optional[Object]:
        """Retrieves an object by its name."""
        key = normalize_identifier(object_name)
        return self.objects.get(key)

    def get_all_entities(self) -> Dict[str, List[Any]]:
        """Returns all registered entities, keyed by type."""
        return {
            "agents": list(self.agents.values()),
            "organizations": list(self.organizations.values()),
            "locations": list(self.locations.values()),
            "objects": list(self.objects.values()),
        }

    def find_entity_by_name(self, name: str, entity_type: str) -> Optional[Any]:
        """Finds an entity by name (fuzzy matching using normalize_for_matching)."""
        logging.debug(f"Finding entity by name: {name} ({entity_type})")
        entities = getattr(self, entity_type)
        for existing_name, entity in entities.items():
            if is_close_match(name, existing_name):
                logging.debug(f"Found close match for {name}: {existing_name}")
                return entity
        logging.debug(f"No close match found for {name} in {entity_type}")
        return None

    def find_entity_by_uuid(self, entity_uuid: str) -> Optional[Any]:
        """Finds an entity of any type by its UUID."""
        logging.debug(f"Finding entity by UUID: {entity_uuid}")
        for entity_type in ["agents", "organizations", "locations", "objects"]:
            entities = getattr(self, entity_type)
            for entity in entities.values():
                if entity.uuid == entity_uuid:
                    logging.debug(f"Found entity with UUID {entity_uuid}: {getattr(entity, 'name', '')}")
                    return entity
        logging.debug(f"No entity found with UUID {entity_uuid}")
        return None

    def merge_duplicate_entities(self, threshold: int = 85) -> None:
        """Merges entities that are likely duplicates (fuzzy name matching).  Uses normalize_for_matching."""
        logging.debug(f"Merging duplicate entities (threshold: {threshold})")
        for entity_type in ["agents", "organizations", "locations", "objects"]:
            entities = list(getattr(self, entity_type).values())
            for i, entity1 in enumerate(entities):
                for j, entity2 in enumerate(entities[i + 1 :]):
                    if is_close_match(entity1.name, entity2.name, threshold):
                        logging.info(f"Merging {entity_type}: {entity1.name} with {entity2.name}")
                        self._merge_entities_by_type(entity_type, entity1, entity2)

    def _merge_entities_by_type(self, entity_type: str, entity1: Any, entity2: Any) -> None:
        """Helper: merge entities based on type."""
        if entity_type == "agents":
            self._merge_agent(entity1, entity2)
        elif entity_type == "organizations":
            self._merge_organization(entity1, entity2)
        elif entity_type == "locations":
            self._merge_location(entity1, entity2)
        elif entity_type == "objects":
            self._merge_object(entity1, entity2)

    def get_agent_name_to_uuid_mapping(self) -> Dict[str, str]:
        """Creates a mapping of agent names (and aliases) to UUIDs.  Uses normalize_name."""
        mapping = {}
        for agent in self.agents.values():
            if agent.name:
                mapping[normalize_name(agent.name)] = agent.uuid
            if hasattr(agent, "aliases") and agent.aliases:
                for alias in agent.aliases:
                    mapping[normalize_name(alias)] = agent.uuid
        return mapping

    async def reconcile_entities(self) -> None:
        """
        Reconciles entities using LLM-assisted resolution.
        """
        old_to_new_uuids = {}  # Track UUID changes during resolution
        
        for entity_type in ["agents", "organizations", "locations", "objects"]:
            logging.info(f"Reconciling {entity_type}...")
            entities = list(getattr(self, entity_type).values())

            if not entities:
                logging.info(f"No {entity_type} to reconcile.")
                continue

            # Store old UUIDs before resolution
            old_uuids = {entity.uuid for entity in entities}

            # Existing resolution code...
            if entity_type == "agents":
                resolved_entities = await b.ResolveAgentCluster(entities=entities)
                new_registry = {
                    entity.uuid: Agent(
                        uuid=entity.uuid,
                        agent_id=entity.agent_id,
                        name=entity.name,
                        title=entity.title,
                        aliases=entity.aliases,
                        description=entity.description,
                        traits=entity.traits,
                        affiliated_org=entity.affiliated_org,
                        sphere_of_influence=entity.sphere_of_influence,
                    )
                    for entity in resolved_entities
                }
            elif entity_type == "organizations":
                resolved_entities = await b.ResolveOrganizationCluster(entities=entities)
                new_registry = {
                    entity.uuid: Organization(
                        uuid=entity.uuid,
                        name=entity.name,
                        description=entity.description,
                        sphere_of_influence=entity.sphere_of_influence,
                        members=entity.members,
                    )
                    for entity in resolved_entities
                }
            elif entity_type == "locations":
                resolved_entities = await b.ResolveLocationCluster(entities=entities)
                new_registry = {
                    entity.uuid: Location(
                        uuid=entity.uuid,
                        name=entity.name,
                        description=entity.description,
                        type=entity.type,
                    )
                    for entity in resolved_entities
                }
            elif entity_type == "objects":
                resolved_entities = await b.ResolveObjectCluster(entities=entities)
                new_registry = {
                    entity.uuid: Object(
                        uuid=entity.uuid,
                        name=entity.name,
                        description=entity.description,
                        purpose=entity.purpose,
                        significance=entity.significance,
                        original_owner=entity.original_owner,
                    )
                    for entity in resolved_entities
                }
            else:
                raise ValueError(f"Unknown entity type: {entity_type}")

            # Track UUID changes
            new_uuids = {entity.uuid for entity in resolved_entities}
            for old_uuid in old_uuids:
                # Find the corresponding new UUID through name matching
                old_entity = next((e for e in entities if e.uuid == old_uuid), None)
                if old_entity and hasattr(old_entity, 'name'):
                    old_entity_name = normalize_for_matching(old_entity.name)
                    new_entity = next((e for e in resolved_entities if hasattr(e, 'name') and normalize_for_matching(e.name) == old_entity_name), None)
                    if new_entity:
                        old_to_new_uuids[old_uuid] = new_entity.uuid
                

            setattr(self, entity_type, new_registry)
            logging.info(f"Reconciliation of {entity_type} complete. {len(resolved_entities)} entities remain.")

        # Update references using the collected UUID changes
        if old_to_new_uuids:
            logging.info(f"Updating {len(old_to_new_uuids)} entity references after resolution...")
            self.update_references_after_resolution(old_to_new_uuids)

    def update_agent_affiliations(self):
        """
        Updates agent affiliated_org fields to match reconciled organization UUIDs.
        Also ensures bidirectional consistency with organization.members lists.
        """
        logging.info("Updating agent affiliations after organization reconciliation...")
        
        # Build maps for both exact and normalized matching
        org_maps = {
            'exact': {org.name: org.uuid for org in self.organizations.values()},
            'normalized': {normalize_for_matching(org.name): org.uuid 
                        for org in self.organizations.values()}
        }

        # Track which agents belong to which orgs for bidirectional updates
        org_to_agents: Dict[str, Set[str]] = defaultdict(set)
        
        for agent in self.agents.values():
            if not agent.affiliated_org:
                continue
                
            # Try exact match first
            new_uuid = org_maps['exact'].get(agent.affiliated_org)
            
            # If no exact match, try normalized match
            if not new_uuid:
                normalized_affiliation = normalize_for_matching(agent.affiliated_org)
                new_uuid = org_maps['normalized'].get(normalized_affiliation)
                
            # If still no match, try fuzzy matching
            if not new_uuid:
                best_match = None
                best_score = 0
                for org_name, org_uuid in org_maps['normalized'].items():
                    score = fuzz.ratio(normalized_affiliation, org_name)
                    if score > 85 and score > best_score:  # Threshold of 85
                        best_score = score
                        best_match = org_uuid
                new_uuid = best_match

            if new_uuid:
                if new_uuid != agent.affiliated_org:
                    logging.debug(
                        f"Updating agent {agent.name}'s affiliated_org from "
                        f"{agent.affiliated_org} to {new_uuid}"
                    )
                    agent.affiliated_org = new_uuid
                org_to_agents[new_uuid].add(agent.uuid)
            else:
                logging.warning(
                    f"No organization match found for affiliation '{agent.affiliated_org}' "
                    f"of agent '{agent.name}'"
                )
                agent.affiliated_org = None  # Clear invalid reference

        # Update organization.members lists for bidirectional consistency
        for org in self.organizations.values():
            org.members = list(org_to_agents.get(org.uuid, set()))
            
        logging.info("Agent affiliations and organization members updated.")

    def update_references_after_resolution(self, old_to_new_uuids: Dict[str, str]) -> None:
        """Updates all entity references after resolution using a mapping of old->new UUIDs"""
        for episode in self.processed_episodes:
            for scene in episode["scenes"]:
                for event in scene["extracted_data"]["events"]:
                    # Update object involvement references
                    updated_involvements = []
                    for involvement_id in event["object_involvements"]:
                        if involvement_id in old_to_new_uuids:
                            updated_involvements.append(old_to_new_uuids[involvement_id])
                        else:
                            updated_involvements.append(involvement_id)
                    event["object_involvements"] = updated_involvements
                    
                    # Update other entity references as needed
                    if "agent_id" in event and event["agent_id"] in old_to_new_uuids:
                        event["agent_id"] = old_to_new_uuids[event["agent_id"]]
                    if "location_id" in event and event["location_id"] in old_to_new_uuids:
                        event["location_id"] = old_to_new_uuids[event["location_id"]]
                    if "organization_id" in event and event["organization_id"] in old_to_new_uuids:
                        event["organization_id"] = old_to_new_uuids[event["organization_id"]]


----- File: ./utils.py -----
# File: utils.py
import uuid
import re
from typing import Dict, Any, Optional
from thefuzz import fuzz

def generate_uuid(entity_type: str, identifier: str) -> str:
    """
    Generates a UUID for a given entity type and identifier.

    Args:
        entity_type: The type of the entity (e.g., "agent", "object", "location").
        identifier: A string identifier unique to the entity within its type.

    Returns:
        A UUID string in the format "entity_type-normalized_identifier".
    """
    normalized_identifier = normalize_identifier(identifier)
    return f"{entity_type}-{normalized_identifier}"

def normalize_identifier(identifier: str) -> str:
    """
    Normalize an identifier for use in UUIDs (Strip, lowercase, and replace spaces with underscores).
    This function is used for creating consistent, unique keys.
    """
    return identifier.strip().lower().replace(" ", "_") if identifier else ""

def normalize_name(name: str) -> str:
    """
    Normalize an entity name for display (strip whitespace, lowercase).
    This function is used for presenting names in a consistent format,
    but NOT for matching or UUID generation.
    """
    return name.strip().lower() if name else ""

def normalize_for_matching(text: str) -> str:
    """
    Normalize text for fuzzy matching (remove punctuation, lowercase, etc.).
    This function is used for comparing strings to find potential duplicates,
    and is more aggressive than normalize_identifier and normalize_name.
    """
    text = text.strip().lower()
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    # Consider adding stemming/lemmatization here if needed, e.g., using NLTK:
    # from nltk.stem import PorterStemmer
    # stemmer = PorterStemmer()
    # text = ' '.join([stemmer.stem(word) for word in text.split()])
    return text

def normalize_reference(text: str) -> str:
    """
    Normalizes a reference string by removing extra whitespace and converting to lowercase.
    Kept for backwards compatibility; consider consolidating with normalize_identifier.
    """
    return re.sub(r"\s+", " ", text.strip().lower())

def validate_reference(reference: str, valid_prefixes: list) -> bool:
    """
    Validates a reference string against a list of valid prefixes.
    Kept for backwards compatibility.
    """
    return any(reference.startswith(prefix) for prefix in valid_prefixes)

def is_close_match(str1: str, str2: str, threshold: int = 80) -> bool:
    """
    Checks if two strings are a close match using fuzzy matching.
    Now uses normalize_for_matching before comparison.

    Args:
        str1: The first string.
        str2: The second string.
        threshold: The minimum similarity score to be considered a match (0-100).

    Returns:
        True if the strings are a close match, False otherwise.
    """
    return fuzz.ratio(normalize_for_matching(str1), normalize_for_matching(str2)) >= threshold

def format_scene_text(scene: Dict[str, Any]) -> str:
    """
    Combines dialogue and stage directions from a scene dictionary into a single text string.
    """
    parts = []
    if "Scene" in scene:
        parts.append(f"Scene: {scene['Scene']}")

    dialogue = scene.get("Dialogue", [])
    for item in dialogue:
        if "Stage Direction" in item:
            parts.append(f"Stage Direction: {item['Stage Direction']}")
        if "Character" in item and "Line" in item:
            parts.append(f"{item['Character']}: {item['Line']}")

    return "\n".join(parts)

