----- File: ./scene_processor.py -----
# File: scene_processor.py
import logging
import json
from typing import Dict, Any, List

from baml_client import b
from baml_client.type_builder import TypeBuilder
from baml_client.types import (
    Agent,
    Organization,
    Location,
    Object,
    Event,
    AgentParticipation,
    ObjectInvolvement
)

from context import GlobalContext
from utils import format_scene_text, generate_uuid, normalize_identifier, is_close_match

async def process_scene_entities(scene: Dict[str, Any], global_context: GlobalContext, scene_number: int) -> str:
    """
    First pass: Extracts and registers entities in dependency order.
    """
    scene_text = format_scene_text(scene)
    story_summary = global_context.get_story_summary()
    tb = TypeBuilder()

    # 1. Extract and Register Locations
    locations = await b.ExtractLocations(
        scene_text=scene_text,
        story_context=story_summary,
        scene_number=scene_number,
        baml_options={"tb": tb}
    )
    for loc in locations:
        global_context.entity_registry.register(loc, "locations")

    # 2. Extract and Register Organizations
    organizations = await b.ExtractOrganizations(
        scene_text=scene_text,
        story_context=story_summary,
        scene_number=scene_number,
        agents=[],  # No agents at this point
        organizations=list(global_context.entity_registry.organizations.values()),
        baml_options={"tb": tb}
    )
    for org in organizations:
        global_context.entity_registry.register(org, "organizations")

    # 3. Extract and Register Agents (using resolved organizations)
    org_enum = tb.add_enum("OrganizationEnum")
    for org in global_context.entity_registry.organizations.values():
        org_enum.add_value(org.uuid)

    # Get the agent name to UUID mapping *before* extracting agents.
    agent_name_to_uuid_mapping = global_context.entity_registry.get_agent_name_to_uuid_mapping()

    # --- Debugging Prints ---
    print("--- Scene Text ---")
    print(scene_text)
    print("--- Story Summary ---")
    print(story_summary)
    print("--- Agent Name to UUID Mapping ---")
    print(agent_name_to_uuid_mapping)

    # IMPORTANT: Supply the mapping as a required positional parameter!
    agents_call = b.ExtractAgents(
        scene_text=scene_text,
        story_context=story_summary,
        agent_name_to_uuid_mapping=agent_name_to_uuid_mapping,  # <-- now provided correctly
        scene_number=scene_number,
        organizations=list(global_context.entity_registry.organizations.values()),
        baml_options={"tb": tb}
    )

    # Await the result from the BAML call.
    agents = await agents_call

    # (If you need to debug the rendered prompt, check your BAML client documentation;
    # usually the awaitable returns the extracted agents and not a prompt property.)

    for agent in agents:
        global_context.entity_registry.register(agent, "agents")

    # 4. Extract and Register Objects (using resolved agents)
    agent_enum = tb.add_enum("AgentEnum")
    for agent in global_context.entity_registry.agents.values():
        agent_enum.add_value(agent.uuid)

    objects = await b.ExtractObjects(
        scene_text=scene_text,
        story_context=story_summary,
        scene_number=scene_number,
        agents=list(global_context.entity_registry.agents.values()),
        baml_options={"tb": tb}
    )
    for obj in objects:
        global_context.entity_registry.register(obj, "objects")

    # Generate a UUID for the scene.
    scene_uuid = generate_uuid("scene", str(scene_number))
    return scene_uuid



async def process_scene_data(scene: Dict[str, Any], global_context: GlobalContext, scene_number: int, scene_uuid: str) -> Dict[str, Any]:
    """
    Second pass: Extracts Scene Metadata, Events, AgentParticipations, and ObjectInvolvements,
    using the already reconciled entities from the global_context.
    """
    scene_text = format_scene_text(scene)
    registry_context = global_context.get_registry_context()
    tb = TypeBuilder()

    # 1. Extract Scene Metadata (using resolved locations)
    location_enum = tb.add_enum("LocationEnum")
    for loc in global_context.entity_registry.locations.values():
        location_enum.add_value(loc.uuid)

    metadata = await b.ExtractSceneMetadata(
        scene_text=scene_text,
        story_context=global_context.get_story_summary(),
        scene_number=scene_number,
        locations=list(global_context.entity_registry.locations.values()), # Pass the locations
        baml_options={"tb": tb}
    )
    metadata.uuid = scene_uuid  # Assign previously generated scene_uuid

    # Normalize the location field
    if metadata and metadata.location:
        normalized_location = "location-" + normalize_identifier(metadata.location)
        registered_location = global_context.entity_registry.get_location(normalized_location)
        if registered_location:
            metadata.location = registered_location.uuid
        else:
            found = False
            for loc in global_context.entity_registry.locations.values():
                if is_close_match(normalized_location, loc.uuid):
                    metadata.location = loc.uuid
                    found = True
                    break
            if not found:
                metadata.location = None

    # 2. Extract Events
    events = await b.ExtractEvents(
        scene_text=scene_text,
        story_context=registry_context,  # Use registry context
        scene_number=scene_number, #Pass the scene_number
        baml_options={"tb": tb}
    )
    # Generate event UUIDs after extracting events.
    for event in events:
        event.uuid = generate_uuid(f"event-{scene_number}", str(event.sequence_within_scene))

    # Sort events by their sequence number and update next_event for each event.
    events.sort(key=lambda e: e.sequence_within_scene)
    for i, event in enumerate(events):
        if i < len(events) - 1:
            event.next_event = events[i+1].uuid
        else:
            event.next_event = None


    # 3. Extract AgentParticipations (using resolved agents and events)
    agent_enum = tb.add_enum("AgentEnum")
    for agent in global_context.entity_registry.agents.values():
        agent_enum.add_value(agent.uuid)
    event_enum = tb.add_enum("EventEnum")
    for event in events:
      event_enum.add_value(event.uuid)

    agent_participations: List[AgentParticipation] = []
    for event in events:
        agent_participations_for_event = await b.ExtractAgentParticipations(
            scene_text=scene_text,
            story_context=registry_context,  # Use registry context
            event=event,
            agents=list(global_context.entity_registry.agents.values()),  # Pass pre-extracted agents
            scene_number=scene_number, # Pass the scene number
            baml_options={"tb": tb}
        )
        for participation in agent_participations_for_event:
            if participation.agent:
                participation.uuid = generate_uuid("agentparticipation", f"{participation.agent}-{event.uuid}")
                agent_participations.append(participation)


    # 4. Extract ObjectInvolvements (using resolved objects and events)
    object_enum = tb.add_enum("ObjectEnum")
    for obj in global_context.entity_registry.objects.values():
        object_enum.add_value(obj.uuid)

    object_involvements: List[ObjectInvolvement] = []
    for event in events:
        object_involvements_for_event = await b.ExtractObjectInvolvements(
            scene_text=scene_text,
            story_context=registry_context,  # Use registry context
            event=event,
            objects=list(global_context.entity_registry.objects.values()),  # Pass pre-extracted objects
            scene_number=scene_number,  # Pass the scene number
            baml_options={"tb": tb}
        )
        for involvement in object_involvements_for_event:
            if involvement.object:
                involvement.uuid = generate_uuid("objectinvolvement", f"{involvement.object}-{event.uuid}")
                object_involvements.append(involvement)

    # Update each event with the IDs of the participation/involvement records.
    for event in events:
        event.agent_participations = [p.uuid for p in agent_participations if p.event == event.uuid]
        event.object_involvements = [i.uuid for i in object_involvements if i.event == event.uuid]

    # Assemble the extracted data.
    extracted_data = {
        "metadata": metadata.model_dump() if metadata else {},
        "events": [e.model_dump() for e in events],
        "agent_participations": [p.model_dump() for p in agent_participations],
        "object_involvements": [i.model_dump() for i in object_involvements]
    }

    # Build the final scene output.
    processed_scene = {
        "scene_uuid": scene_uuid,
        "original_scene_data": scene,
        "extracted_data": extracted_data
    }
    return processed_scene

----- File: ./concatenate.py -----
import os
import glob


def concatenate_python_files(folder_path, output_file="combined_code.txt"):
    """
    Concatenates all Python files in a folder into a single text file.

    Args:
        folder_path: The path to the folder containing the Python files.
        output_file: The name of the output text file (default: "combined_code.txt").
    """

    if not os.path.isdir(folder_path):
        print(f"Error: '{folder_path}' is not a valid directory.")
        return

    python_files = glob.glob(os.path.join(folder_path, "*.py"))
    
    # Add the specific .baml file
    baml_file = "/home/user/langchain/baml_src/myth06.baml"
    all_files_to_concatenate = python_files + [baml_file]

    if not python_files:
        print(f"No Python files found in '{folder_path}'.")
        return

    try:
        with open(output_file, "w", encoding="utf-8") as outfile:
            for file_path in all_files_to_concatenate:
                if os.path.exists(file_path):
                    try:
                        with open(file_path, "r", encoding="utf-8") as infile:
                            outfile.write(f"----- File: {file_path} -----\n")
                            outfile.write(infile.read())
                            outfile.write("\n\n")
                    except UnicodeDecodeError:
                        print(f"Warning: Could not decode file {file_path} using utf-8, skipping this file")
                else:
                  print(f"Warning: Could not find file {file_path}, skipping")

            

            


        print(f"Successfully concatenated {len(python_files)} Python files into '{output_file}'.")

    except Exception as e:
        print(f"An error occurred: {e}")

# Example usage:
folder_to_scan = "."  # Replace with the actual folder path if needed.
concatenate_python_files(folder_to_scan)


----- File: ./episode_processor.py -----
# File: episode_processor.py
import asyncio
import logging
from typing import Dict, Any

from scene_processor import process_scene_entities, process_scene_data  # Import both functions
from context import GlobalContext
from utils import format_scene_text, generate_uuid # Import the missing functions

# Configure logging
logging.basicConfig(filename='episode_processing.log', level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

async def process_episode(episode: Dict[str, Any], global_context: GlobalContext) -> Dict[str, Any]:
    """
    Process a single episode by iterating over its scenes.
    Supports both direct scene arrays and nested acts.
    Uses a two-pass approach:
    1. process_scene_entities (extracts entities in dependency order)
    2. process_scene_data (extracts events, participations, using reconciled entities)
    """
    processed_scenes = []
    episode_title = episode.get("Episode", "Untitled Episode")

    logging.info(f"Starting processing for episode: {episode_title}")

    # --- First Pass: Extract Entities ---
    scene_uuids = []  # Store scene UUIDs for the second pass
    if "Acts" in episode:
        scene_number = 0
        for act_index, act in enumerate(episode.get("Acts", [])):
            act_scenes = act.get("Scenes", [])
            logging.info(f"Processing act {act_index + 1} (entity extraction)")
            for scene in act_scenes:
                scene_number += 1
                logging.info(f"Processing scene {scene_number} (entity extraction): {scene.get('Scene', 'Unnamed Scene')}")
                try:
                    scene_uuid = await process_scene_entities(scene, global_context, scene_number)
                    scene_uuids.append((scene_number, scene_uuid))  # Store scene number and UUID
                except Exception as e:
                    logging.error(f"Error processing scene {scene_number} (entity extraction): {e}", exc_info=True)
                    # Consider skipping the scene on error

    elif "Scenes" in episode:
        scene_number = 0
        for scene in episode.get("Scenes", []):
            scene_number += 1
            logging.info(f"Processing scene {scene_number} (entity extraction): {scene.get('Scene', 'Unnamed Scene')}")
            try:
                scene_uuid = await process_scene_entities(scene, global_context, scene_number)
                scene_uuids.append((scene_number, scene_uuid)) # Store scene number and UUID
            except Exception as e:
                logging.error(f"Error processing scene {scene_number} (entity extraction): {e}", exc_info=True)
            # Consider skipping the scene on error
    else:
        logging.error(f"Episode structure not recognized: must contain 'Scenes' or 'Acts'.")
        raise ValueError("Episode structure not recognized: must contain 'Scenes' or 'Acts'.")


    # --- Second Pass: Extract Scene Data ---
    logging.info(f"Starting second pass (event/participation extraction) for episode: {episode_title}")
    for scene_number, scene_uuid in scene_uuids:
        # Find the original scene data based on scene_number
        original_scene = None
        if "Acts" in episode:
            for act in episode.get("Acts", []):
                for scene in act.get("Scenes", []):
                    # Format the scene text and check if it matches the UUID
                    temp_scene_text = format_scene_text(scene)
                    temp_scene_uuid = generate_uuid("scene", str(scene_number))  # Generate UUID the same way
                    if temp_scene_uuid == scene_uuid:
                        original_scene = scene
                        break
                if original_scene:
                    break
        elif "Scenes" in episode:
            for scene in episode.get("Scenes", []):
                temp_scene_text = format_scene_text(scene)
                temp_scene_uuid = generate_uuid("scene", str(scene_number))
                if temp_scene_uuid == scene_uuid:
                    original_scene = scene
                    break

        if original_scene is None:
            logging.error(f"Could not find original scene data for scene number {scene_number} (UUID: {scene_uuid})")
            continue # Or raise an exception if you want to halt processing

        logging.info(f"Processing scene {scene_number} (event/participation extraction)")
        try:
            logging.info(f"Calling process_scene_data for scene {scene_number} with UUID {scene_uuid}") #NEW LOGGING STATEMENT
            processed_scene = await process_scene_data(original_scene, global_context, scene_number, scene_uuid)
            logging.info(f"process_scene_data completed for scene {scene_number}") # NEW LOGGING STATEMENT
            processed_scenes.append(processed_scene)
        except Exception as e:
            logging.error(f"Error processing scene {scene_number} (event/participation extraction): {e}", exc_info=True)
            # Consider skipping the scene

     # Update each scene’s metadata to point to the next scene’s UUID.
    for i in range(len(processed_scenes) - 1):
        current_scene_metadata = processed_scenes[i]["extracted_data"]["metadata"]
        next_scene_uuid = processed_scenes[i+1]["scene_uuid"]
        current_scene_metadata["next_scene"] = next_scene_uuid
    if processed_scenes:
        processed_scenes[-1]["extracted_data"]["metadata"]["next_scene"] = None

    logging.info(f"Finished processing episode: {episode_title}")

    processed_episode = {
        "episode_title": episode_title,
        "scenes": processed_scenes
    }

    return processed_episode

----- File: ./validation.py -----
# File: validation.py
import logging
from typing import Any, Dict
from baml_client.types import Agent, Organization, Location, Object, Event, AgentParticipation, ObjectInvolvement
from context import GlobalContext # Import GlobalContext
from entity_registry import EntityRegistry  # <---- CORRECTED IMPORT STATEMENT


def validate_entity_attributes(entity: Any) -> bool:
    """
    Validates the attributes of an entity (Agent, Organization, Location, Object).

    Args:
        entity: The entity to validate.

    Returns:
        True if the entity is valid, False otherwise.
    """
    if isinstance(entity, Agent):
        if not entity.uuid or not entity.uuid.startswith("agent-"):
            logging.error(f"Invalid agent UUID: {entity.uuid}")
            return False
        if not entity.name:
            logging.error(f"Agent {entity.uuid} has no name.")
            return False
        if entity.affiliated_org and not entity.affiliated_org.startswith("org-"):
            logging.error(f"Agent {entity.uuid} has invalid affiliated_org: {entity.affiliated_org}")
            return False

    elif isinstance(entity, Organization):
        if not entity.uuid or not entity.uuid.startswith("org-"):
            logging.error(f"Invalid organization UUID: {entity.uuid}")
            return False
        if not entity.name:
            logging.error(f"Organization {entity.uuid} has no name.")
            return False
        # Add more Organization-specific checks if needed

    elif isinstance(entity, Location):
        if not entity.uuid or not entity.uuid.startswith("location-"):
            logging.error(f"Invalid location UUID: {entity.uuid}")
            return False
        if not entity.name:
            logging.error(f"Location {entity.uuid} has no name.")
            return False

    elif isinstance(entity, Object):
        if not entity.uuid or not entity.uuid.startswith("object-"):
            logging.error(f"Invalid object UUID: {entity.uuid}")
            return False
        if not entity.name:
            logging.error(f"Object {entity.uuid} has no name.")
            return False

    else:
        logging.error(f"Unknown entity type: {type(entity)}")
        return False

    return True

def validate_relationships(global_context: GlobalContext) -> bool: # Pass GlobalContext
    """
    Validates the relationships in the entity registry.
    """
    all_valid = True
    entity_registry = global_context.entity_registry

    # Agent.affiliated_org -> Organization.members []
    for agent in entity_registry.agents.values():
        if agent.affiliated_org:
            org = entity_registry.get_organization(agent.affiliated_org)
            if not org:
                logging.error(f"Validation Error: Agent {agent.uuid} has affiliated_org '{agent.affiliated_org}' but organization not found.")
                all_valid = False
            elif agent.uuid not in (org.members or []): # Check if agent UUID is in org members
                logging.error(f"Validation Error: Agent {agent.uuid} affiliated_org '{agent.affiliated_org}' but agent not in organization members.")
                all_valid = False

    # Object.original_owner -> Agent.uuid
    for obj in entity_registry.objects.values():
        if obj.original_owner:
            owner_agent = entity_registry.get_agent(obj.original_owner)
            if not owner_agent:
                logging.error(f"Validation Error: Object {obj.uuid} has original_owner '{obj.original_owner}' but agent not found.")
                all_valid = False

    # ObjectInvolvement.object -> Object.uuid
    for event_data in global_context.processed_episodes:
        for scene_data in event_data["scenes"]:
            for involvement_data in scene_data["extracted_data"]["object_involvements"]:
                if not validate_object_involvement(involvement_data, entity_registry):
                  all_valid = False

    # AgentParticipation.agent -> Agent.uuid
    for event_data in global_context.processed_episodes:
        for scene_data in event_data["scenes"]:
            for participation_data in scene_data["extracted_data"]["agent_participations"]:
                if not validate_agent_participation(participation_data, entity_registry):
                  all_valid = False

    # SceneMetadata.location -> Location.uuid
    for event_data in global_context.processed_episodes:
        for scene_data in event_data["scenes"]:
            metadata_data = scene_data["extracted_data"]["metadata"]
            if metadata_data and metadata_data.get("location"): # Check if metadata and location exist
                location_uuid = metadata_data["location"]
                location = entity_registry.get_location(location_uuid)
                if not location:
                    logging.error(f"Validation Error: SceneMetadata {metadata_data.get('uuid')} refers to location '{location_uuid}' but location not found.")
                    all_valid = False

    # Event.agent_participations -> AgentParticipation.uuid [] (Forward reference check - UUIDs are generated later, can't fully validate here)
    # Event.object_involvements -> ObjectInvolvement.uuid [] (Forward reference check - UUIDs are generated later, can't fully validate here)
    # SceneMetadata.scene_number -> scene_number (variable) - Covered by other validation
    # Scene.scene_number -> scene_number (variable) - Covered by other validation
    # Scene.next_scene -> Scene.uuid (of next scene) or null (more complex, can add later if needed)
    # Event.next_event -> Event.uuid (of next event) or null (more complex, can add later if needed)


    return all_valid


def validate_scene_consistency(scene_data: Dict[str, Any]) -> bool:
    """
    Performs consistency checks within a scene.

    Args:
        scene_data: The processed scene data.

    Returns:
        True if the scene is consistent, False otherwise.
    """
    # Add scene consistency checks here (e.g., event sequence numbers, agent/object references)
    return True

def validate_all(global_context: "GlobalContext") -> bool:
    """
    Performs all validations on the given global context.
    """
    all_valid = True

    # Validate entity attributes
    for entity_type, entities in global_context.entity_registry.get_all_entities().items():
        for entity in entities:
            if not validate_entity_attributes(entity):
                logging.error(f"Invalid entity: {entity_type} - {entity.uuid}")
                all_valid = False

    # Validate relationships - CALL THE NEW FUNCTION
    if not validate_relationships(global_context): # Call the new relationship validation
        all_valid = False

    # Validate scene consistency (currently a placeholder)
    for episode in global_context.processed_episodes:
        for scene in episode["scenes"]:
            if not validate_scene_consistency(scene):
                all_valid = False

    return all_valid

def validate_object_involvement(involvement_data: Dict[str, Any], entity_registry: EntityRegistry) -> bool:
    """
    Validates an ObjectInvolvement record.
    """
    if not involvement_data.get("object"):
        logging.error(f"Invalid ObjectInvolvement data: Missing 'object' field.")
        return False

    if not involvement_data.get("event"):
        logging.error(f"Invalid ObjectInvolvement data: Missing 'event' field.")
        return False

    involved_object = entity_registry.get_object(involvement_data["object"])
    if not involved_object:
        logging.error(f"Validation Error: ObjectInvolvement refers to object '{involvement_data['object']}' but object not found.")
        return False

    # Ensure event UUID is valid
    if not involvement_data["event"].startswith("event-"):
        logging.error(f"Validation Error: ObjectInvolvement refers to event '{involvement_data['event']}' with invalid UUID format.")
        return False

    return True

def validate_agent_participation(participation_data: Dict[str, Any], entity_registry: EntityRegistry) -> bool:
    """
    Validates an AgentParticipation record.
    """
    if not participation_data.get("agent"):
        logging.error(f"Invalid AgentParticipation data: Missing 'agent' field.")
        return False

    if not participation_data.get("event"):
        logging.error(f"Invalid AgentParticipation data: Missing 'event' field.")
        return False

    participating_agent = entity_registry.get_agent(participation_data["agent"])
    if not participating_agent:
        logging.error(f"Validation Error: AgentParticipation refers to agent '{participation_data['agent']}' but agent not found.")
        return False

    # Ensure event UUID is valid
    if not participation_data["event"].startswith("event-"):
        logging.error(f"Validation Error: AgentParticipation refers to event '{participation_data['event']}' with invalid UUID format.")
        return False

    return True

----- File: ./main.py -----
# File: main.py
import asyncio
import json
import logging
import sys
import json
from pathlib import Path
from typing import List

from episode_processor import process_episode
from context import GlobalContext
from validation import validate_all
from utils import normalize_name # NEW IMPORT
from entity_registry import EntityRegistry


import logging
for handler in logging.root.handlers[:]:
    logging.root.removeHandler(handler)
# Configure logging
logging.basicConfig(
    filename="fabula_processing.log",
    level=logging.DEBUG,
    format="%(asctime)s - %(levelname)s - %(message)s",
)

# Define paths for input and output files
INPUT_JSON_PATH = Path("/home/user/fabula/source_docs/ai_fanfic/star_trek_tng/echoes_of_the_past_transcript.json")
CONTEXT_FILES = [
    Path("/home/user/fabula/source_docs/ai_fanfic/star_trek_tng/echoes_of_the_past_treatment.txt")
]
OUTPUT_JSON_PATH = Path("echoes_of_the_past_graph_GPT4mini.json")

# INPUT_JSON_PATH = Path("dummy_data/fault_lines_transcript.json")
# CONTEXT_FILES = [
#     Path("dummy_data/fault_lines_novelization.txt")
# ]
# OUTPUT_JSON_PATH = Path("fault_lines_graph.json")

# OUTPUT_JSON_PATH = Path("output/test_graph.json")

# INPUT_JSON_PATH = Path("dummy_data/networking_event_transcript.json")
# CONTEXT_FILES = [
#     Path("dummy_data/networking_event_treatment.txt")
# ]
# OUTPUT_JSON_PATH = Path("output/networking_event_graph.json")

def load_context_documents(context_files: List[Path]) -> str:
    """Loads and concatenates context documents."""
    context_text = ""
    for filepath in context_files:
        with open(filepath, "r") as f:
            context_text += f.read() + "\n"
    return context_text

def convert_to_serializable(obj):
    """
    Recursively convert Pydantic objects to dictionaries for JSON serialization.
    """
    if isinstance(obj, list):
        return [convert_to_serializable(item) for item in obj]
    elif isinstance(obj, dict):
        return {k: convert_to_serializable(v) for k, v in obj.items()}
    elif hasattr(obj, "model_dump"):
        return obj.model_dump()
    else:
        return obj

async def main():
    """
    Orchestrates the complete processing of a narrative script.
    Loads the script JSON, processes episodes, updates the global context,
    and outputs the final structured JSON.  Uses a two-pass approach with
    dependency-based entity extraction.
    """
    logging.info("Starting Fabula processing...")

    script_data = None
    context_documents = ""
    
    # First check for command-line input file
    if len(sys.argv) > 1:
        input_path = Path(sys.argv[1])
        if not input_path.exists():
            logging.error(f"Input file not found: {input_path}")
            return
        logging.info(f"Loading script data from: {input_path}")
        try:
            with open(input_path, "r") as f:
                script_data = json.load(f)
        except json.JSONDecodeError as e:
            logging.error(f"Failed to parse JSON from {input_path}: {e}")
            return
            
        # Check for additional context files from command line
        if len(sys.argv) > 2:
            context_files = [Path(filepath) for filepath in sys.argv[2:]]
            context_documents = load_context_documents(context_files)
    
    # If no command line arguments, check for default input file
    elif INPUT_JSON_PATH.exists():
        logging.info(f"Loading script data from default path: {INPUT_JSON_PATH}")
        try:
            with open(INPUT_JSON_PATH, "r") as f:
                script_data = json.load(f)
        except json.JSONDecodeError as e:
            logging.error(f"Failed to parse JSON from {INPUT_JSON_PATH}: {e}")
            return
            
        # Load default context files
        if CONTEXT_FILES:
            existing_context_files = [Path(filepath) for filepath in CONTEXT_FILES if Path(filepath).exists()]
            if existing_context_files:
                context_documents = load_context_documents(existing_context_files)
    
    # If no input file found, use test data
    else:
        logging.info("No input file provided. Using test data.")
        script_data = {
            "Story": "Frontier in Space",
            "Airdate": "1973-02-24",
            "Episodes": [
                {
                    "Episode": "Episode One",
                    "Scenes": [
                        {
                            "Scene": "Spaceship Bridge",
                            "Dialogue": [
                                {
                                    "Stage Direction": "A spaceship is travelling between star systems."
                                },
                                {
                                    "Character": "HARDY",
                                    "Line": "We shall be entering hyperspace in fifty seconds."
                                },
                                {
                                    "Character": "STEWART",
                                    "Line": "Do you know what I'd like?"
                                }
                            ]
                        }
                    ]
                },
                {
                    "Episode": "Episode Two",
                    "Acts": [
                        {
                            "Act": "Act One",
                            "Scenes": [
                                {
                                    "Scene": "Control Room",
                                    "Dialogue": [
                                        {
                                            "Stage Direction": "The control room buzzes with activity."
                                        },
                                        {
                                            "Character": "CAPTAIN",
                                            "Line": "Prepare for jump!"
                                        }
                                    ]
                                }
                            ]
                        },
                        {
                            "Act": "Act Two",
                            "Scenes": [
                                {
                                    "Scene": "Engine Room",
                                    "Dialogue": [
                                        {
                                            "Stage Direction": "The engine room hums with power."
                                        },
                                        {
                                            "Character": "TECHNICIAN",
                                            "Line": "All systems are green."
                                        }
                                    ]
                                }
                            ]
                        }
                    ]
                }
            ]
        }
        context_documents = ""  # Or load default context if applicable

    # Add support for context files, if provided
    if len(sys.argv) > 2:  # Check for command line arguments for context files
        context_documents = load_context_documents([Path(filepath) for filepath in sys.argv[2:]])
    else:  # Use default context files, if they exist
        context_documents = load_context_documents([Path(filepath) for filepath in CONTEXT_FILES if Path(filepath).exists()]) # Use list comprehension for safety
    # Initialize GlobalContext with context documents
    global_context = GlobalContext(context_documents)

    # **ADD THIS CHECK: Skip processing if script_data is None (error already logged)**
    if script_data is None:
        logging.error("No script data loaded. Aborting processing.")
        return

    episodes = script_data.get("Episodes", [])
    processed_episodes = []

    logging.info("Starting episode processing (two-pass)...")
    for episode_index, episode in enumerate(episodes):
        logging.info(f"Processing episode {episode_index + 1}: {episode.get('Episode', 'Untitled Episode')}")
        processed_episode = await process_episode(episode, global_context)  # process_episode now handles BOTH passes
        processed_episodes.append(processed_episode)
    logging.info("Finished episode processing.")

    # --- Entity Reconciliation (after ALL episodes are processed) ---
    logging.info("Starting entity reconciliation...")
    await global_context.entity_registry.reconcile_entities()  # Await the async function
    logging.info("Entity reconciliation complete.")

    # After processing episodes, attach them to the global context.
    global_context.processed_episodes = processed_episodes

    # --- Remapping (as a final safety net) ---
    #Remove all the remapping - we have to resolve the core problem, not patch it
    #logging.info("Starting remapping...")
    #agent_name_to_uuid = global_context.entity_registry.get_agent_name_to_uuid_mapping()
    #entity_registry = global_context.entity_registry

    #for episode in processed_episodes:
    #    for scene in episode["scenes"]:
    #        extracted_data = scene["extracted_data"]

            # Remap agent_participations
    #        for participation in extracted_data["agent_participations"]:
    #            if participation["agent"] in agent_name_to_uuid:
    #                participation["agent"] = agent_name_to_uuid[participation["agent"]]
    #            elif entity_registry.find_entity_by_uuid(participation["agent"]):
    #              #If already a UUID, pass
    #              pass
    #            else:
    #                logging.warning(f"Agent participation refers to unknown agent: {participation['agent']}")

            # Remap object_involvements
    #        for involvement in extracted_data["object_involvements"]:
                # Check for name-based references and remap if possible
    #            if involvement["object"] in {obj.name: obj.uuid for obj in entity_registry.objects.values()}:
    #                involvement["object"] = {obj.name: obj.uuid for obj in entity_registry.objects.values()}[involvement["object"]]
    #            elif entity_registry.find_entity_by_uuid(involvement["object"]):
                    # If already a UUID, pass
    #                pass
    #            else:
    #                logging.warning(f"Object involvement refers to unknown object: {involvement['object']}")


            #Remap original owners in objects
    #        for obj in entity_registry.objects.values():
    #            if obj.original_owner:
    #                if obj.original_owner in agent_name_to_uuid:
    #                    obj.original_owner = agent_name_to_uuid[obj.original_owner]
    #                elif entity_registry.find_entity_by_uuid(obj.original_owner):
                        # If already a UUID, pass
    #                    pass
    #                else:
    #                    logging.warning(f"Object refers to unknown original owner: {obj.original_owner}")

            #Remap locations in scene metadata
    #        metadata = extracted_data["metadata"]
    #        if metadata.get("location"):
    #            location_uuid = metadata["location"]

    #            if location_uuid in {loc.name: loc.uuid for loc in entity_registry.locations.values()}:
    #                metadata["location"] = {loc.name: loc.uuid for loc in entity_registry.locations.values()}[location_uuid]
    #            elif entity_registry.find_entity_by_uuid(location_uuid):
                    #If already a valid UUID, pass
    #                pass
    #            else:
    #                logging.warning(f"Scene metadata refers to unknown location: {location_uuid}")


    #logging.info("Remapping complete.")

    # Validate the output (now that the global context contains the updated processed episodes)
    logging.info("Validating extracted data...")
    if validate_all(global_context):
        logging.info("Validation successful.")
    else:
        logging.error("Validation failed. Check logs for details.")

    final_output = {
        "story_title": script_data.get("Story", "Untitled Story"),
        "airdate": script_data.get("Airdate"),
        "episodes": processed_episodes,  # Include processed episodes
        "entity_registry": global_context.entity_registry.get_all_entities()
    }

    # Convert the output to a JSON-serializable format
    serializable_output = convert_to_serializable(final_output)

    # Log the final output
    logging.info("Final output:")
    logging.info(json.dumps(serializable_output, indent=4))

    # Write the output to a file
    with open(OUTPUT_JSON_PATH, "w") as f:
        json.dump(serializable_output, f, indent=4)
    logging.info(f"Fabula processing complete. Output written to {OUTPUT_JSON_PATH}")

if __name__ == "__main__":
    asyncio.run(main())

----- File: ./post_processor.py -----
# post_processor.py
from typing import Dict, Any, Union
from entity_normalizer import EntityNormalizer
import logging

logger = logging.getLogger(__name__)

def clean_entity_references(data: Dict[str, Any]) -> Dict[str, Any]:
    """Clean up entity references in the extracted data."""
    if 'entity_registry' in data:
        # Build a map of normalized names to correct entity types
        entity_map = {}
        for entity_type in ['agents', 'objects', 'locations', 'organizations']:
            registry = data['entity_registry'].get(entity_type, {})
            for uuid, entity in registry.items():
                normalized_name = EntityNormalizer.normalize_name(entity['name'])
                if normalized_name in entity_map:
                    logger.warning(
                        f"Found duplicate entity '{normalized_name}' as both "
                        f"{entity_map[normalized_name][0]} and {entity_type}"
                    )
                entity_map[normalized_name] = (entity_type, uuid)

        # Clean up references using the map
        for entity_type in ['agents', 'objects', 'locations', 'organizations']:
            registry = data['entity_registry'].get(entity_type, {})
            clean_registry = {}
            for uuid, entity in registry.items():
                normalized_name = EntityNormalizer.normalize_name(entity['name'])
                correct_type, correct_uuid = entity_map.get(normalized_name, (entity_type, uuid))
                if correct_type == entity_type:
                    clean_registry[uuid] = entity
            data['entity_registry'][entity_type] = clean_registry

    return data

def clean_scene_references(scene_data: Dict[str, Any], normalizer: EntityNormalizer) -> None:
    """Clean up references within a scene's extracted data."""
    # Clean metadata location reference
    if 'metadata' in scene_data and scene_data['metadata'].get('location'):
        location_ref = normalizer.extract_uuid(scene_data['metadata']['location'])
        if not normalizer.validate_reference(location_ref):
            try:
                scene_data['metadata']['location'] = normalizer.normalize_reference(
                    'location', location_ref
                )
            except Exception as e:
                logger.warning(f"Failed to normalize location reference: {e}")
                scene_data['metadata']['location'] = None

    # Clean event references
    if 'events' in scene_data:
        for event in scene_data['events']:
            # Clean agent participations
            if 'agent_participations' in event:
                cleaned_participations = []
                for ap in event['agent_participations']:
                    ap_ref = normalizer.extract_uuid(ap)
                    if normalizer.validate_reference(ap_ref):
                        cleaned_participations.append(ap_ref)
                event['agent_participations'] = cleaned_participations

            # Clean object involvements
            if 'object_involvements' in event:
                cleaned_involvements = []
                for oi in event['object_involvements']:
                    oi_ref = normalizer.extract_uuid(oi)
                    if normalizer.validate_reference(oi_ref):
                        cleaned_involvements.append(oi_ref)
                event['object_involvements'] = cleaned_involvements

    # Clean agent participations
    if 'agent_participations' in scene_data:
        for ap in scene_data['agent_participations']:
            if 'agent' in ap:
                agent_ref = normalizer.extract_uuid(ap['agent'])
                if not normalizer.validate_reference(agent_ref):
                    try:
                        ap['agent'] = normalizer.normalize_reference('agent', agent_ref)
                    except Exception as e:
                        logger.warning(f"Failed to normalize agent reference: {e}")
                        ap['agent'] = None

    # Clean object involvements
    if 'object_involvements' in scene_data:
        for oi in scene_data['object_involvements']:
            if 'object' in oi:
                object_ref = normalizer.extract_uuid(oi['object'])
                if not normalizer.validate_reference(object_ref):
                    try:
                        oi['object'] = normalizer.normalize_reference('object', object_ref)
                    except Exception as e:
                        logger.warning(f"Failed to normalize object reference: {e}")
                        oi['object'] = None


def update_event_involvements(data: Dict) -> Dict:
    """Update object involvement counts based on events."""
    object_involvements = {}
    
    # Count involvements across all scenes
    for episode in data['episodes']:
        for scene in episode['scenes']:
            if 'extracted_data' in scene:
                for event in scene['extracted_data'].get('events', []):
                    for obj_uuid in event.get('object_involvements', []):
                        object_involvements[obj_uuid] = object_involvements.get(obj_uuid, 0) + 1
    
    # Update objects with involvement counts
    if 'entity_registry' in data and 'objects' in data['entity_registry']:
        for obj_uuid in data['entity_registry']['objects']:
            if obj_uuid in object_involvements:
                data['entity_registry']['objects'][obj_uuid]['event_involvements'] = object_involvements[obj_uuid]
            else:
                data['entity_registry']['objects'][obj_uuid]['event_involvements'] = 0
    
    return data

----- File: ./context.py -----
# context.py

import uuid
from typing import Dict, Any, List, Union, Type, Optional, cast
from baml_client.types import Agent, Organization, Location, Object
from utils import normalize_identifier, is_close_match, generate_uuid
from entity_registry import EntityRegistry # <---- CORRECTED IMPORT STATEMENT

def normalize_name(name: str) -> str:
    """
    Normalize an entity name by stripping whitespace and converting to lowercase.
    """
    return name.strip().lower() if name else ""

class GlobalContext:
    """
    The GlobalContext holds story-wide shared state, including:
      - The entity registry, which tracks all agents, objects, locations, and organizations.
      - Scene summaries to help build a cohesive story context for BAML calls.
    """

    def __init__(self, context_documents: str = ""):
        self.entity_registry = EntityRegistry()
        # Keep a list of scene metadata summaries (for example, scene titles).
        self.scene_summaries: List[Dict[str, Any]] = []
        self.context_documents = context_documents
        self.processed_episodes: List[Any] = []

    def update_with_scene(self, extracted_data: Dict[str, Any]) -> None:
        """
        Update the global context using extracted data from a scene.
        Typically, we add the scene metadata to our context.
        """
        metadata = extracted_data.get("metadata", {})
        if metadata:
            self.scene_summaries.append(metadata)

    def get_story_summary(self) -> str:
        """
        Generates a summary string of the current story context based on the global context.
        Includes scene summaries and optionally context documents.
        """
        summary_lines = []

        # Add context documents to the summary
        if self.context_documents:
            summary_lines.append("Context Documents:")
            summary_lines.append(self.context_documents)

        # Summarize scene metadata
        if self.scene_summaries:
            summary_lines.append("Scene Summaries:")
            for scene_data in self.scene_summaries:
                summary_lines.append(
                    f"  Scene: {scene_data.get('title', 'Untitled')}, UUID: {scene_data.get('uuid', 'N/A')}, Location: {scene_data.get('location', 'N/A')}"
                )

        return "\n".join(summary_lines)

    def get_registry_context(self) -> str:
        """
        Generates a context string summarizing the current state of the entity registry.
        """
        summary_lines = []

        # Summarize entities
        entities = self.entity_registry.get_all_entities()
        for entity_type, entity_list in entities.items():
            if entity_list:
                summary_lines.append(f"{entity_type.capitalize()}:")
                for entity in entity_list:
                    if entity_type == "agents":
                        summary_lines.append(
                            f"  Agent: {entity.name}, UUID: {entity.uuid}, Affiliated Org: {entity.affiliated_org}"
                        )
                    elif entity_type == "organizations":
                        summary_lines.append(
                            f"  Organization: {entity.name}, UUID: {entity.uuid}, Members: {', '.join(entity.members or [])}"
                        )
                    elif entity_type == "locations":
                        summary_lines.append(
                            f"  Location: {entity.name}, UUID: {entity.uuid}, Type: {entity.type}"
                        )
                    elif entity_type == "objects":
                        summary_lines.append(
                            f"  Object: {entity.name}, UUID: {entity.uuid}, Original Owner: {entity.original_owner}"
                        )

        return "\n".join(summary_lines)

----- File: ./entity_registry.py -----
# entity_registry.py
from typing import Dict, Any, List, Union, cast, Optional
import logging
from thefuzz import fuzz
from baml_client.types import Agent, Organization, Location, Object, ResolvedAgent, ResolvedOrganization, ResolvedLocation, ResolvedObject
from utils import generate_uuid, normalize_identifier, normalize_name, normalize_for_matching, is_close_match
from baml_client import b

class EntityRegistry:
    """
    Maintains distinct collections of primary entities (agents, organizations, locations, objects)
    using native BAML types. Ensures consistent entity references.
    """

    def __init__(self):
        self.agents: Dict[str, Agent] = {}
        self.organizations: Dict[str, Organization] = {}
        self.locations: Dict[str, Location] = {}
        self.objects: Dict[str, Object] = {}

    def register(self, entity: Any, entity_type: str) -> None:
        """Registers or merges an entity into the registry based on type."""
        logging.debug(f"Registering entity of type: {entity_type}")
        if entity_type == "agents":
            self.register_agent(cast(Agent, entity))
        elif entity_type == "organizations":
            self.register_organization(cast(Organization, entity))
        elif entity_type == "locations":
            self.register_location(cast(Location, entity))
        elif entity_type == "objects":
            self.register_object(cast(Object, entity))
        else:
            logging.error(f"Unknown entity type: {entity_type}")
            raise ValueError(f"Unknown entity type: {entity_type}")

    def register_agent(self, agent: Agent) -> None:
        """Registers or updates an agent, handling duplicates and orgs."""

        identifier = agent.agent_id if agent.agent_id else agent.name
        if not identifier:
            logging.error("Agent must have a name or an agent_id.")
            return

        # 1. Check for existing agent by UUID (fastest and most reliable)
        existing_agent = self.find_entity_by_uuid(agent.uuid)
        if existing_agent:
            logging.debug(f"Agent with UUID {agent.uuid} already exists. Merging...")
            self._merge_agent(existing_agent, agent)
            return  # CRITICAL: Return after merging by UUID

        # 2. Check for potential duplicates by name/aliases (using normalize_for_matching)
        for existing_agent in self.agents.values():
            if is_close_match(agent.name, existing_agent.name):
                logging.debug(f"Potential duplicate agent found (name match). Merging...")
                self._merge_agent(existing_agent, agent)
                return # Return after merging
            if hasattr(agent, "aliases") and agent.aliases:
                for alias in agent.aliases:
                    if is_close_match(alias, existing_agent.name):
                        logging.debug(f"Potential duplicate agent found (alias match). Merging...")
                        self._merge_agent(existing_agent, agent)
                        return # Return after merging

        # 3. Add new agent to the registry
        logging.debug(f"Adding new agent {agent.name} with UUID {agent.uuid}.")
        key = agent.uuid # Use LLM UUID as the key
        self.agents[key] = agent

    def _merge_agent(self, existing_agent: Agent, new_agent: Agent) -> None:
        """Merges new agent data into the existing agent record, KEEPING EXISTING UUID."""
        logging.debug(f"Merging agent {existing_agent.uuid} ({existing_agent.name}) with new data.")

        # Prioritize existing values, but update if new data is present and different
        if new_agent.name and new_agent.name != existing_agent.name:
            logging.debug(f"Updating agent name from {existing_agent.name} to {new_agent.name}")
            existing_agent.name = new_agent.name
        if new_agent.title is not None and new_agent.title != existing_agent.title:
            existing_agent.title = new_agent.title
        if new_agent.description is not None and new_agent.description != existing_agent.description:
            existing_agent.description = new_agent.description
        if new_agent.traits:
            existing_agent.traits = list(
                set(existing_agent.traits or []) | set(new_agent.traits)
            )
        if new_agent.affiliated_org and new_agent.affiliated_org != existing_agent.affiliated_org:
            existing_agent.affiliated_org = new_agent.affiliated_org
        if new_agent.sphere_of_influence is not None and new_agent.sphere_of_influence != existing_agent.sphere_of_influence:
            existing_agent.sphere_of_influence = new_agent.sphere_of_influence

        # Merge aliases only if the attribute exists in both
        if hasattr(existing_agent, "aliases") and hasattr(new_agent, "aliases"):
            existing_agent.aliases = list(
                set(existing_agent.aliases or []) | set(new_agent.aliases or [])
            )

    def get_agent(self, agent_id: str) -> Optional[Agent]:
        """Retrieves an agent by its ID (using normalize_identifier)."""
        return self.agents.get(agent_id)


    def register_organization(self, org: Organization) -> None:
        """Registers or updates an organization."""
        logging.debug(f"Registering organization: {org.name}")

        # Check for existing by UUID
        existing_org = self.find_entity_by_uuid(org.uuid)
        if existing_org:
            logging.debug(f"Organization with UUID {org.uuid} already exists. Merging...")
            self._merge_organization(existing_org, org)
            return

        # Check for potential duplicates by name (using normalize_for_matching)
        for existing_org in self.organizations.values():
            if is_close_match(org.name, existing_org.name):
                logging.debug(f"Potential duplicate organization found (name match). Merging...")
                self._merge_organization(existing_org, org)
                return

        # Add new organization
        logging.debug(f"Adding new organization {org.name} with UUID {org.uuid}.")
        key = org.uuid # Use LLM UUID for the key
        self.organizations[key] = org


    def _merge_organization(self, existing_org: Organization, new_org: Organization) -> None:
        """Merges new organization data into the existing record, KEEPING EXISTING UUID."""
        logging.debug(f"Merging organization {existing_org.uuid} ({existing_org.name}) with new data.")

        if new_org.name and new_org.name != existing_org.name:
            logging.info(f"Updating org name from {existing_org.name} to {new_org.name}")
            existing_org.name = new_org.name
        if new_org.description is not None and new_org.description != existing_org.description:
            existing_org.description = new_org.description
        if new_org.sphere_of_influence and new_org.sphere_of_influence != "Unknown" and new_org.sphere_of_influence != existing_org.sphere_of_influence:
            existing_org.sphere_of_influence = new_org.sphere_of_influence
        if new_org.members:
            existing_org.members = list(
                set(existing_org.members or []) | set(new_org.members)
            )

    def get_organization(self, org_id: str) -> Optional[Organization]:
        """Retrieves an organization by its ID."""
        key = normalize_identifier(org_id)
        return self.organizations.get(key)

    def register_location(self, location: Location) -> None:
        """Registers or updates a location."""
        logging.debug(f"Registering location: {location.name}")

        # Check by UUID
        existing_location = self.find_entity_by_uuid(location.uuid)
        if existing_location:
            logging.debug(f"Location {location.name} exists. Merging...")
            self._merge_location(existing_location, location)
            return

        # Check for duplicates by name
        for existing_location in self.locations.values():
            if is_close_match(location.name, existing_location.name):
                 logging.debug(f"Potential duplicate location found (name match). Merging...")
                 self._merge_location(existing_location, location)
                 return

        # Add new
        logging.debug(f"Adding new location {location.name} to registry.")
        key = location.uuid # Use the LLM UUID as the Key
        self.locations[key] = location

    def _merge_location(self, existing_location: Location, new_location: Location) -> None:
        """Merges new location data into the existing record, KEEPING EXISTING UUID."""
        logging.debug(f"Merging location {existing_location.uuid} ({existing_location.name}) with new data.")
        if new_location.name and new_location.name != existing_location.name:
            logging.debug(f"Updating location name to {new_location.name}")
            existing_location.name = new_location.name
        if new_location.description is not None and new_location.description != existing_location.description:
            existing_location.description = new_location.description
        if new_location.type is not None and new_location.type != existing_location.type:
            existing_location.type = new_location.type

    def get_location(self, location_name: str) -> Optional[Location]:
        """Retrieves a location by its name."""
        key = normalize_identifier(location_name)
        return self.locations.get(key)

    def register_object(self, obj: Object) -> None:
        """Registers or updates an object."""
        logging.debug(f"Registering object: {obj.name}")

        # Check by UUID
        existing_object = self.find_entity_by_uuid(obj.uuid)
        if existing_object:
            logging.debug(f"Object {obj.name} exists. Merging...")
            self._merge_object(existing_object, obj)
            return

        # Check for duplicates by name
        for existing_object in self.objects.values():
            if is_close_match(obj.name, existing_object.name):
                logging.debug(f"Potential duplicate object found (name match). Merging...")
                self._merge_object(existing_object, obj)
                return

        # Add new
        logging.debug(f"Adding new object {obj.name} to registry.")
        key = obj.uuid # Use LLM UUID as key
        self.objects[key] = obj

    def _merge_object(self, existing_obj: Object, new_obj: Object) -> None:
        """Merges new object data into the existing record, KEEPING EXISTING UUID."""
        logging.debug(f"Merging object {existing_obj.uuid} ({existing_obj.name}) with new data.")
        if new_obj.name and new_obj.name != existing_obj.name:
            logging.debug(f"Updating object name to {new_obj.name}")
            existing_obj.name = new_obj.name
        if new_obj.description is not None and new_obj.description != existing_obj.description:
            existing_obj.description = new_obj.description
        if new_obj.purpose is not None and new_obj.purpose != existing_obj.purpose:
            existing_obj.purpose = new_obj.purpose
        if new_obj.significance is not None and new_obj.significance != existing_obj.significance:
            existing_obj.significance = new_obj.significance
        if new_obj.original_owner and new_obj.original_owner != existing_obj.original_owner:
            existing_obj.original_owner = new_obj.original_owner

    def get_object(self, object_name: str) -> Optional[Object]:
        """Retrieves an object by its name."""
        key = normalize_identifier(object_name)
        return self.objects.get(key)

    def get_all_entities(self) -> Dict[str, List[Any]]:
        """Returns all registered entities, keyed by type."""
        return {
            "agents": list(self.agents.values()),
            "organizations": list(self.organizations.values()),
            "locations": list(self.locations.values()),
            "objects": list(self.objects.values()),
        }

    def find_entity_by_name(self, name: str, entity_type: str) -> Optional[Any]:
        """Finds an entity by name (fuzzy matching using normalize_for_matching)."""
        logging.debug(f"Finding entity by name: {name} ({entity_type})")
        entities = getattr(self, entity_type)
        for existing_name, entity in entities.items():
            if is_close_match(name, existing_name):
                logging.debug(f"Found close match for {name}: {existing_name}")
                return entity
        logging.debug(f"No close match found for {name} in {entity_type}")
        return None

    def find_entity_by_uuid(self, entity_uuid: str) -> Optional[Any]:
        """Finds an entity of any type by its UUID."""
        logging.debug(f"Finding entity by UUID: {entity_uuid}")
        for entity_type in ["agents", "organizations", "locations", "objects"]:
            entities = getattr(self, entity_type)
            for entity in entities.values():
                if entity.uuid == entity_uuid:
                    logging.debug(f"Found entity with UUID {entity_uuid}: {getattr(entity, 'name', '')}")
                    return entity
        logging.debug(f"No entity found with UUID {entity_uuid}")
        return None

    def merge_duplicate_entities(self, threshold: int = 85) -> None:
        """Merges entities that are likely duplicates (fuzzy name matching).  Uses normalize_for_matching."""
        logging.debug(f"Merging duplicate entities (threshold: {threshold})")
        for entity_type in ["agents", "organizations", "locations", "objects"]:
            entities = list(getattr(self, entity_type).values())
            for i, entity1 in enumerate(entities):
                for j, entity2 in enumerate(entities[i + 1 :]):
                    if is_close_match(entity1.name, entity2.name, threshold):
                        logging.info(f"Merging {entity_type}: {entity1.name} with {entity2.name}")
                        self._merge_entities_by_type(entity_type, entity1, entity2)

    def _merge_entities_by_type(self, entity_type: str, entity1: Any, entity2: Any) -> None:
        """Helper: merge entities based on type."""
        if entity_type == "agents":
            self._merge_agent(entity1, entity2)
        elif entity_type == "organizations":
            self._merge_organization(entity1, entity2)
        elif entity_type == "locations":
            self._merge_location(entity1, entity2)
        elif entity_type == "objects":
            self._merge_object(entity1, entity2)

    def get_agent_name_to_uuid_mapping(self) -> Dict[str, str]:
        """Creates a mapping of agent names (and aliases) to UUIDs.  Uses normalize_name."""
        mapping = {}
        for agent in self.agents.values():
            if agent.name:
                mapping[normalize_name(agent.name)] = agent.uuid
            if hasattr(agent, "aliases") and agent.aliases:
                for alias in agent.aliases:
                    mapping[normalize_name(alias)] = agent.uuid
        return mapping

    async def reconcile_entities(self) -> None:
        """
        Reconciles entities using LLM-assisted resolution.  Converts from
        Resolved* types back to the original entity types.
        """
        for entity_type in ["agents", "organizations", "locations", "objects"]:
            logging.info(f"Reconciling {entity_type}...")
            entities = list(getattr(self, entity_type).values())

            if not entities:
                logging.info(f"No {entity_type} to reconcile.")
                continue

            # Call the appropriate BAML resolution function
            if entity_type == "agents":
                resolved_entities = await b.ResolveAgentCluster(entities=entities)
                # Convert ResolvedAgent back to Agent
                new_registry = {
                    entity.uuid: Agent(
                        uuid=entity.uuid,
                        agent_id=entity.agent_id,
                        name=entity.name,
                        title=entity.title,
                        aliases=entity.aliases,
                        description=entity.description,
                        traits=entity.traits,
                        affiliated_org=entity.affiliated_org,
                        sphere_of_influence=entity.sphere_of_influence,
                    )
                    for entity in resolved_entities
                }
            elif entity_type == "organizations":
                resolved_entities = await b.ResolveOrganizationCluster(entities=entities)
                # Convert ResolvedOrganization back to Organization
                new_registry = {
                    entity.uuid: Organization(
                        uuid=entity.uuid,
                        name=entity.name,
                        description=entity.description,
                        sphere_of_influence=entity.sphere_of_influence,
                        members=entity.members,
                    )
                    for entity in resolved_entities
                }
            elif entity_type == "locations":
                resolved_entities = await b.ResolveLocationCluster(entities=entities)
                # Convert ResolvedLocation back to Location
                new_registry = {
                    entity.uuid: Location(
                        uuid=entity.uuid,
                        name=entity.name,
                        description=entity.description,
                        type=entity.type,
                    )
                    for entity in resolved_entities
                }
            elif entity_type == "objects":
                resolved_entities = await b.ResolveObjectCluster(entities=entities)
                # Convert ResolvedObject back to Object
                new_registry = {
                    entity.uuid: Object(
                        uuid=entity.uuid,
                        name=entity.name,
                        description=entity.description,
                        purpose=entity.purpose,
                        significance=entity.significance,
                        original_owner=entity.original_owner,
                    )
                    for entity in resolved_entities
                }
            else:
                raise ValueError(f"Unknown entity type: {entity_type}")

            # Replace the existing entity list with the resolved and converted entities
            setattr(self, entity_type, new_registry)
            logging.info(f"Reconciliation of {entity_type} complete. {len(resolved_entities)} entities remain.")

----- File: ./utils.py -----
# File: utils.py
import uuid
import re
from typing import Dict, Any, Optional
from thefuzz import fuzz

def generate_uuid(entity_type: str, identifier: str) -> str:
    """
    Generates a UUID for a given entity type and identifier.

    Args:
        entity_type: The type of the entity (e.g., "agent", "object", "location").
        identifier: A string identifier unique to the entity within its type.

    Returns:
        A UUID string in the format "entity_type-normalized_identifier".
    """
    normalized_identifier = normalize_identifier(identifier)
    return f"{entity_type}-{normalized_identifier}"

def normalize_identifier(identifier: str) -> str:
    """
    Normalize an identifier for use in UUIDs (Strip, lowercase, and replace spaces with underscores).
    This function is used for creating consistent, unique keys.
    """
    return identifier.strip().lower().replace(" ", "_") if identifier else ""

def normalize_name(name: str) -> str:
    """
    Normalize an entity name for display (strip whitespace, lowercase).
    This function is used for presenting names in a consistent format,
    but NOT for matching or UUID generation.
    """
    return name.strip().lower() if name else ""

def normalize_for_matching(text: str) -> str:
    """
    Normalize text for fuzzy matching (remove punctuation, lowercase, etc.).
    This function is used for comparing strings to find potential duplicates,
    and is more aggressive than normalize_identifier and normalize_name.
    """
    text = text.strip().lower()
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    # Consider adding stemming/lemmatization here if needed, e.g., using NLTK:
    # from nltk.stem import PorterStemmer
    # stemmer = PorterStemmer()
    # text = ' '.join([stemmer.stem(word) for word in text.split()])
    return text

def normalize_reference(text: str) -> str:
    """
    Normalizes a reference string by removing extra whitespace and converting to lowercase.
    Kept for backwards compatibility; consider consolidating with normalize_identifier.
    """
    return re.sub(r"\s+", " ", text.strip().lower())

def validate_reference(reference: str, valid_prefixes: list) -> bool:
    """
    Validates a reference string against a list of valid prefixes.
    Kept for backwards compatibility.
    """
    return any(reference.startswith(prefix) for prefix in valid_prefixes)

def is_close_match(str1: str, str2: str, threshold: int = 80) -> bool:
    """
    Checks if two strings are a close match using fuzzy matching.
    Now uses normalize_for_matching before comparison.

    Args:
        str1: The first string.
        str2: The second string.
        threshold: The minimum similarity score to be considered a match (0-100).

    Returns:
        True if the strings are a close match, False otherwise.
    """
    return fuzz.ratio(normalize_for_matching(str1), normalize_for_matching(str2)) >= threshold

def format_scene_text(scene: Dict[str, Any]) -> str:
    """
    Combines dialogue and stage directions from a scene dictionary into a single text string.
    """
    parts = []
    if "Scene" in scene:
        parts.append(f"Scene: {scene['Scene']}")

    dialogue = scene.get("Dialogue", [])
    for item in dialogue:
        if "Stage Direction" in item:
            parts.append(f"Stage Direction: {item['Stage Direction']}")
        if "Character" in item and "Line" in item:
            parts.append(f"{item['Character']}: {item['Line']}")

    return "\n".join(parts)

